{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d40anh2Y3Q_H"
      },
      "source": [
        "# **Laboratorio 04  SIS421**\n",
        "\n",
        "### Nombre: Quispe Sucullani Jose David\n",
        "\n",
        "### C.U. 111-376\n",
        "\n",
        "### Link github:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oIJnb63G3kwF"
      },
      "source": [
        "##Contexto del Laboratorio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "sCaNiEq7J_CP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b1271a70-6110-4434-bf1c-a63581701f8b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import os\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets, transforms\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmhQ7-wuHuyh"
      },
      "source": [
        "##1: Lectura del Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvQ35sjHHsHo",
        "outputId": "5bdce159-bdd9-450b-e9a0-87dd1e8ee3ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de imágenes de entrenamiento: 60000\n",
            "Número de imágenes de prueba: 10000\n"
          ]
        }
      ],
      "source": [
        "# Definir las transformaciones para las imágenes\n",
        "from torchvision import datasets, transforms\n",
        "import torch.utils.data\n",
        "\n",
        "# Definir las transformaciones para el conjunto de datos FashionMNIST\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((28, 28)),  # Redimensionar las imágenes a 28x28 píxeles para FashionMNIST\n",
        "    transforms.ToTensor(),  # Convertir las imágenes a tensores\n",
        "    transforms.Normalize([0.5], [0.5])  # Normalizar entre [-1, 1] para las imágenes en escala de grises\n",
        "])\n",
        "\n",
        "# Cargar el conjunto de datos de entrenamiento y prueba de FashionMNIST con las transformaciones\n",
        "train_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_data = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Mostrar la cantidad de imágenes de entrenamiento y prueba\n",
        "print(f\"Número de imágenes de entrenamiento: {len(train_data)}\")\n",
        "print(f\"Número de imágenes de prueba: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "-qkHfbG1H2TB"
      },
      "outputs": [],
      "source": [
        "# Function to handle dataset limiting (not needed for FashionMNIST, so keeping it as is but it won't be used directly)\n",
        "def limit_dataset_size(root_dir, max_per_class=6000):\n",
        "    # Dictionary to store paths of selected images by class\n",
        "    limited_dataset = []\n",
        "\n",
        "    # Iterate through subfolders in root_dir (each subfolder is a class)\n",
        "    for class_name in os.listdir(root_dir):\n",
        "        class_dir = os.path.join(root_dir, class_name)\n",
        "        if os.path.isdir(class_dir):\n",
        "            # Get all images in the subfolder\n",
        "            all_images = os.listdir(class_dir)\n",
        "            # Filter to get only images, excluding other file types\n",
        "            all_images = [os.path.join(class_name, img) for img in all_images if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "            # Randomly select 6000 images\n",
        "            selected_images = random.sample(all_images, min(len(all_images), max_per_class))\n",
        "            limited_dataset.extend(selected_images)\n",
        "\n",
        "    return limited_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3Dd71InH5Ty",
        "outputId": "a64e9d7d-4adc-4fdf-c329-cdab8a188c5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número total de imágenes en el nuevo conjunto de entrenamiento: 60000\n",
            "Distribución de imágenes por clase: Counter({9: 6000, 0: 6000, 3: 6000, 2: 6000, 7: 6000, 5: 6000, 1: 6000, 6: 6000, 4: 6000, 8: 6000})\n"
          ]
        }
      ],
      "source": [
        "# For FashionMNIST, we don't need a custom dataset class to limit size.\n",
        "# The train_data loaded in the previous cell is already the full dataset.\n",
        "\n",
        "# Verify the number of images in the training set (already done in the previous cell)\n",
        "print(f\"Número total de imágenes en el nuevo conjunto de entrenamiento: {len(train_data)}\")\n",
        "\n",
        "# Verify the number of images per class (FashionMNIST is balanced)\n",
        "from collections import Counter\n",
        "# Get the targets from the train_data object\n",
        "class_distribution = Counter(train_data.targets.tolist())\n",
        "print(\"Distribución de imágenes por clase:\", class_distribution)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWDkI2v7H9S5",
        "outputId": "ecdaa28e-f0de-498b-eea3-b65005cb96fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clases en el conjunto de entrenamiento: ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
            "Cantidad de clases: 10\n"
          ]
        }
      ],
      "source": [
        "# 1. Ver las etiquetas del dataset (clases):\n",
        "# Ver las classes del dataset (etiquetas) for FashionMNIST\n",
        "print(f\"Clases en el conjunto de entrenamiento: {train_data.classes}\")\n",
        "print(f\"Cantidad de clases: {len(train_data.classes)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPcWQPvjIF3Q",
        "outputId": "485884f0-7057-40e5-8c64-eda9b811f450"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número total de imágenes en el conjunto de entrenamiento: 60000\n",
            "Número de clases: 10\n",
            "Clase 'Ankle boot' tiene 6000 imágenes\n",
            "Clase 'T-shirt/top' tiene 6000 imágenes\n",
            "Clase 'Dress' tiene 6000 imágenes\n",
            "Clase 'Pullover' tiene 6000 imágenes\n",
            "Clase 'Sneaker' tiene 6000 imágenes\n",
            "Clase 'Sandal' tiene 6000 imágenes\n",
            "Clase 'Trouser' tiene 6000 imágenes\n",
            "Clase 'Shirt' tiene 6000 imágenes\n",
            "Clase 'Coat' tiene 6000 imágenes\n",
            "Clase 'Bag' tiene 6000 imágenes\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from collections import Counter\n",
        "\n",
        "# Verify the total number of images in the training set\n",
        "num_total_images = len(train_data)\n",
        "print(f\"Número total de imágenes en el conjunto de entrenamiento: {num_total_images}\")\n",
        "\n",
        "# Verify the number of classes (labels) for FashionMNIST\n",
        "num_classes = len(train_data.classes)\n",
        "print(f\"Número de clases: {num_classes}\")\n",
        "\n",
        "# Get the labels of all images (train_data.targets has the labels for each image)\n",
        "class_distribution = Counter(train_data.targets.tolist())\n",
        "\n",
        "# Show how many images are in each class\n",
        "for class_idx, count in class_distribution.items():\n",
        "    print(f\"Clase '{train_data.classes[class_idx]}' tiene {count} imágenes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "5lp4KxDpL0xD",
        "outputId": "6ccdf57b-b90a-4b01-a27d-27b12a55ea78"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Get the classes from the dataset\n",
        "classes = train_data.classes\n",
        "\n",
        "# Convert images and labels to numpy arrays for easier processing\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # Desnormalize\n",
        "    npimg = img.numpy()\n",
        "    # FashionMNIST is grayscale, so we handle it differently\n",
        "    if npimg.shape[0] == 1:\n",
        "        npimg = np.transpose(npimg, (1, 2, 0))[:, :, 0] # Remove the single channel dimension\n",
        "    else:\n",
        "        npimg = np.transpose(npimg, (1, 2, 0))\n",
        "    return npimg\n",
        "\n",
        "# Show 10 random images\n",
        "plt.figure(figsize=(10, 5))\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i + 1)\n",
        "    index = random.randint(0, len(train_data) - 1)\n",
        "    img, label = train_data[index]\n",
        "    plt.imshow(imshow(img), cmap='gray') # Use gray colormap for grayscale images\n",
        "    plt.title(classes[label])\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aspzm1KmttH"
      },
      "source": [
        "El dataset está formado por 6000 imágenes de baja resolución (50 x 50 píxeles, con tres canales de colores) y contiene 10 tipos prentas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "mQbp3CFL1Hst"
      },
      "outputs": [],
      "source": [
        "# Define a custom class for the dataset that normalizes to [-1, 1] (already handled by transform)\n",
        "# We can just use the loaded train_data directly with the DataLoader\n",
        "class Prendas(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataset):\n",
        "        self.imgs = torch.stack([img[0] for img in dataset])  # Load images as tensors\n",
        "        # Normalization to [-1, 1] is done in the transform\n",
        "        self.labels = torch.tensor([img[1] for img in dataset], dtype=torch.long)  # Image labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.imgs[idx], self.labels[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "IxG0WzM81KA2"
      },
      "outputs": [],
      "source": [
        "# We don't need to create a separate normalized dataset class for FashionMNIST\n",
        "# The normalization is done in the transform when loading the data.\n",
        "# We will use the original 'train_data' with the DataLoader.\n",
        "train_dataset = train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "bfM3xlPT1XLY"
      },
      "outputs": [],
      "source": [
        "# Split images into batches\n",
        "dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bH_Cv5e90qek"
      },
      "source": [
        "#**MODELO DCGANs**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "up0WzC2nuost"
      },
      "source": [
        "2. Definir el Generador (Generator)\n",
        "Ahora, ajustamos el generador para manejar imágenes a color (3 canales) de tamaño 50x50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "GYhXoOGuus1M"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.input_size = 100  # Size of the random input vector (latent vector)\n",
        "\n",
        "        self.inp = nn.Sequential(\n",
        "            nn.Linear(self.input_size, 7*7*256),  # Transform the input vector to a 7x7x256 feature map for 28x28 output\n",
        "            nn.BatchNorm1d(7*7*256),  # Batch normalization for stable training\n",
        "            nn.ReLU(True)\n",
        "        )\n",
        "\n",
        "        self.main = nn.Sequential(\n",
        "            # First deconvolutional layer: 7x7x256 -> 14x14x128\n",
        "            nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            # Second deconvolutional layer: 14x14x128 -> 28x28x64\n",
        "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            # Third deconvolutional layer: 28x28x64 -> 28x28x1 (Grayscale)\n",
        "            nn.ConvTranspose2d(64, 1, 3, stride=1, padding=1, bias=False), # Adjusted kernel size and stride for 28x28 output\n",
        "            nn.Tanh()  # Normalize the output to a [-1, 1] range\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.inp(x)\n",
        "        x = x.view(-1, 256, 7, 7)  # Reshape for 7x7 input with 256 channels\n",
        "        x = self.main(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LR2UaGBF2N8l",
        "outputId": "8c2c765d-e614-4293-ffd9-5fb1095c8815"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "# Verify the output size\n",
        "generator = Generator()\n",
        "output = generator(torch.randn(64, 100))\n",
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1G3VfjtAu6p9"
      },
      "source": [
        "###3. Definir el Discriminador (Discriminator)\n",
        "Modificamos el discriminador para aceptar imágenes a color de tamaño 50x50:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "OYEn586UvCXV"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.main = nn.Sequential(\n",
        "            # First convolutional layer: 28x28x1 -> 14x14x64\n",
        "            nn.Conv2d(1, 64, 4, stride=2, padding=1, bias=False), # Input channels changed to 1\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            # Second convolutional layer: 14x14x64 -> 7x7x128\n",
        "            nn.Conv2d(64, 128, 4, stride=2, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            # Third convolutional layer: 7x7x128 -> 4x4x256\n",
        "            nn.Conv2d(128, 256, 3, stride=2, padding=1, bias=False), # Adjusted kernel size\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            # Fourth convolutional layer: 4x4x256 -> 2x2x512 (or similar depending on padding/stride)\n",
        "            # Let's adjust the last conv layer for 4x4 to 1x1 output\n",
        "            nn.Conv2d(256, 512, 4, stride=1, padding=0, bias=False), # Adjusted kernel size and padding for 1x1 output\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2, inplace=True)\n",
        "        )\n",
        "\n",
        "        self.out = nn.Sequential(\n",
        "            # Linear layer for classification\n",
        "            nn.Linear(512*1*1, 1),  # Flatten the output tensor from the convolutional layer (now 1x1x512)\n",
        "            nn.Sigmoid()  # Output between 0 and 1\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.main(x)  # Pass the input through the convolutional layers\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
        "        x = self.out(x)  # Pass through the final linear layer\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wu73_hh2wr0",
        "outputId": "35f95869-79bf-4022-a59d-ff6383f52ac6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([64, 1])\n"
          ]
        }
      ],
      "source": [
        "discriminator = Discriminator()\n",
        "# Adjust the input size to match FashionMNIST images (grayscale 28x28)\n",
        "output = discriminator(torch.randn(64, 1, 28, 28))\n",
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5StKBi1vG81"
      },
      "source": [
        "###4. Definimos el Proceso de Entrenamiento\n",
        "Configuramos el bucle de entrenamiento, la función de pérdida y los optimizadores:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "IJeF8KtLvKmU"
      },
      "outputs": [],
      "source": [
        "from fastprogress import master_bar, progress_bar\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def fit(g, d, dataloader, epochs=25, crit=None, checkpoint_dir='/content/drive/MyDrive/SIS421-IA2/Laboratorios/LAB-04/', save_interval=5):\n",
        "    g.to(device)\n",
        "    d.to(device)\n",
        "\n",
        "    g_optimizer = torch.optim.Adam(g.parameters(), lr=3e-4)\n",
        "    d_optimizer = torch.optim.Adam(d.parameters(), lr=3e-4)\n",
        "\n",
        "    crit = nn.BCEWithLogitsLoss() if crit is None else crit\n",
        "\n",
        "    g_loss, d_loss = [], []\n",
        "    mb = master_bar(range(1, epochs+1))\n",
        "    hist = {'g_loss': [], 'd_loss': []}\n",
        "\n",
        "    # Create the checkpoint directory if it doesn't exist\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        os.makedirs(checkpoint_dir)\n",
        "\n",
        "    for epoch in mb:\n",
        "        for X, _ in progress_bar(dataloader, parent=mb):\n",
        "            X = X.to(device)  # Ensure real images go to the device\n",
        "\n",
        "            # Train the discriminator\n",
        "            g.eval()\n",
        "            d.train()\n",
        "\n",
        "            # Generate a batch of fake images\n",
        "            noise = torch.randn((X.size(0), g.input_size)).to(device)  # Noise vector\n",
        "            generated_images = g(noise)  # Generate fake images\n",
        "\n",
        "            # Concatenate real and generated images for the discriminator\n",
        "            d_input = torch.cat([generated_images, X], dim=0)\n",
        "            # Create labels: 0 for fake images and 1 for real images\n",
        "            d_gt = torch.cat([torch.zeros(X.size(0)), torch.ones(X.size(0))]).view(-1, 1).to(device)\n",
        "\n",
        "            # Optimize the discriminator\n",
        "            d_optimizer.zero_grad()\n",
        "            d_output = d(d_input)\n",
        "            d_l = crit(d_output, d_gt)\n",
        "            d_l.backward()\n",
        "            d_optimizer.step()\n",
        "            d_loss.append(d_l.item())\n",
        "\n",
        "            # Train the generator\n",
        "            g.train()\n",
        "            d.eval()\n",
        "\n",
        "            # Generate a new batch of fake images\n",
        "            noise = torch.randn((X.size(0), g.input_size)).to(device)\n",
        "            generated_images = g(noise)\n",
        "\n",
        "            # Pass the fake images through the discriminator\n",
        "            d_output = d(generated_images)\n",
        "            # Generator's goal: fool the discriminator, so we use \"real\" labels (1)\n",
        "            g_gt = torch.ones(X.size(0)).view(-1, 1).to(device)\n",
        "\n",
        "            # Optimize the generator\n",
        "            g_optimizer.zero_grad()\n",
        "            g_l = crit(d_output, g_gt)\n",
        "            g_l.backward()\n",
        "            g_optimizer.step()\n",
        "            g_loss.append(g_l.item())\n",
        "\n",
        "            # Progress logs\n",
        "            mb.child.comment = f'g_loss {np.mean(g_loss):.5f} d_loss {np.mean(d_loss):.5f}'\n",
        "        mb.write(f'Epoch {epoch}/{epochs} g_loss {np.mean(g_loss):.5f} d_loss {np.mean(d_loss):.5f}')\n",
        "        hist['g_loss'].append(np.mean(g_loss))\n",
        "        hist['d_loss'].append(np.mean(d_loss))\n",
        "\n",
        "\n",
        "        # Save a checkpoint every 'save_interval' epochs\n",
        "        if epoch % save_interval == 0:\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'generator_state_dict': g.state_dict(),\n",
        "                'discriminator_state_dict': d.state_dict(),\n",
        "                'g_optimizer_state_dict': g_optimizer.state_dict(),\n",
        "                'd_optimizer_state_dict': d_loss\n",
        "            }, os.path.join(checkpoint_dir, f'GANs_modelo_{epoch}.pth'))\n",
        "\n",
        "    return hist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "id": "IVntp3UGFnZc",
        "outputId": "db8e8d18-d97e-4b4c-bbc5-bd9b732324f3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Epoch 1/25 g_loss 9.61136 d_loss 0.00484<p>Epoch 2/25 g_loss 10.58206 d_loss 0.00296<p>Epoch 3/25 g_loss 10.19094 d_loss 0.00921<p>Epoch 4/25 g_loss 8.81633 d_loss 0.02119<p>Epoch 5/25 g_loss 8.08889 d_loss 0.02868<p>Epoch 6/25 g_loss 7.60731 d_loss 0.03233<p>Epoch 7/25 g_loss 7.24990 d_loss 0.03681<p>Epoch 8/25 g_loss 6.94185 d_loss 0.04215<p>Epoch 9/25 g_loss 6.66288 d_loss 0.04816<p>Epoch 10/25 g_loss 6.39597 d_loss 0.05602<p>Epoch 11/25 g_loss 6.14682 d_loss 0.06416<p>Epoch 12/25 g_loss 5.91866 d_loss 0.07263<p>Epoch 13/25 g_loss 5.71953 d_loss 0.08078<p>Epoch 14/25 g_loss 5.54060 d_loss 0.08810<p>Epoch 15/25 g_loss 5.37934 d_loss 0.09479<p>Epoch 16/25 g_loss 5.23425 d_loss 0.10066<p>Epoch 17/25 g_loss 5.10628 d_loss 0.10590<p>Epoch 18/25 g_loss 4.99274 d_loss 0.11070<p>Epoch 19/25 g_loss 4.88708 d_loss 0.11520<p>Epoch 20/25 g_loss 4.79370 d_loss 0.11897<p>Epoch 21/25 g_loss 4.70925 d_loss 0.12246<p>Epoch 22/25 g_loss 4.63215 d_loss 0.12561<p>Epoch 23/25 g_loss 4.56173 d_loss 0.12841<p>Epoch 24/25 g_loss 4.49712 d_loss 0.13109<p>Epoch 25/25 g_loss 4.43697 d_loss 0.13362"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Ejecuta el entrenamiento\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "hist = fit(generator, discriminator, dataloader, crit=torch.nn.BCELoss())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCWeC1UDcNLt"
      },
      "source": [
        "## CONTINUANDO CON EL ENTRENAMIENTO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "ykN766VRcZvF"
      },
      "outputs": [],
      "source": [
        "from fastprogress import master_bar, progress_bar\n",
        "\n",
        "def load_checkpoint(checkpoint_path, g, d, g_optimizer, d_optimizer):\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    g.load_state_dict(checkpoint['generator_state_dict'])\n",
        "    d.load_state_dict(checkpoint['discriminator_state_dict'])\n",
        "    g_optimizer.load_state_dict(checkpoint['g_optimizer_state_dict'])\n",
        "    d_optimizer.load_state_dict(checkpoint['d_optimizer_state_dict'])\n",
        "    start_epoch = checkpoint['epoch'] + 1  # Reanudar desde el siguiente epoch\n",
        "    g_loss = checkpoint['g_loss']\n",
        "    d_loss = checkpoint['d_loss']\n",
        "    return start_epoch, g_loss, d_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Celda 3: Definición de la función fit (incluye load_checkpoint)\n",
        "# Reemplaza la definición existente de fit con este código\n",
        "def fit(g, d, dataloader, epochs=25, crit=None, checkpoint_dir='/content/drive/MyDrive/SIS421-IA2/Laboratorios/LAB-04/', save_interval=5, resume_from_checkpoint=None):\n",
        "    g.to(device)\n",
        "    d.to(device)\n",
        "\n",
        "    g_optimizer = torch.optim.Adam(g.parameters(), lr=3e-4)\n",
        "    d_optimizer = torch.optim.Adam(d.parameters(), lr=3e-4)\n",
        "\n",
        "    crit = nn.BCEWithLogitsLoss() if crit is None else crit\n",
        "\n",
        "    # Helper function to load checkpoint (defined inside fit to ensure correct version is used)\n",
        "    def load_checkpoint(checkpoint_path, g, d, g_optimizer, d_optimizer):\n",
        "        checkpoint = torch.load(checkpoint_path)\n",
        "        g.load_state_dict(checkpoint['generator_state_dict'])\n",
        "        d.load_state_dict(checkpoint['discriminator_state_dict'])\n",
        "        g_optimizer.load_state_dict(checkpoint['g_optimizer_state_dict'])\n",
        "        d_optimizer.load_state_dict(checkpoint['d_optimizer_state_dict'])\n",
        "        start_epoch = checkpoint['epoch'] + 1\n",
        "        g_loss = checkpoint.get('g_loss', [])\n",
        "        d_loss = checkpoint.get('d_loss', [])\n",
        "        print(f\"Checkpoint loaded from epoch {checkpoint.get('epoch', 'N/A')}\")\n",
        "        return start_epoch, g_loss, d_loss\n",
        "\n",
        "\n",
        "    if resume_from_checkpoint:\n",
        "        try:\n",
        "            start_epoch, g_loss, d_loss = load_checkpoint(resume_from_checkpoint, g, d, g_optimizer, d_optimizer)\n",
        "            print(f\"Resuming training from epoch {start_epoch}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading checkpoint: {e}\")\n",
        "            print(\"Starting training from scratch instead.\")\n",
        "            start_epoch = 1\n",
        "            g_loss, d_loss = [], []\n",
        "    else:\n",
        "        start_epoch = 1\n",
        "        g_loss, d_loss = [], []\n",
        "\n",
        "    mb = master_bar(range(start_epoch, epochs+1))\n",
        "    hist = {'g_loss': g_loss, 'd_loss': d_loss}\n",
        "\n",
        "\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        os.makedirs(checkpoint_dir)\n",
        "\n",
        "    for epoch in mb:\n",
        "        current_epoch_g_loss = []\n",
        "        current_epoch_d_loss = []\n",
        "\n",
        "        for X, _ in progress_bar(dataloader, parent=mb):\n",
        "            X = X.to(device)\n",
        "\n",
        "            g.eval()\n",
        "            d.train()\n",
        "\n",
        "            noise = torch.randn((X.size(0), g.input_size)).to(device)\n",
        "            generated_images = g(noise)\n",
        "\n",
        "            d_input = torch.cat([generated_images, X], dim=0)\n",
        "            d_gt = torch.cat([torch.zeros(X.size(0)), torch.ones(X.size(0))]).view(-1, 1).to(device)\n",
        "\n",
        "            d_optimizer.zero_grad()\n",
        "            d_output = d(d_input)\n",
        "            d_l = crit(d_output, d_gt)\n",
        "            d_l.backward()\n",
        "            d_optimizer.step()\n",
        "            current_epoch_d_loss.append(d_l.item())\n",
        "\n",
        "\n",
        "            g.train()\n",
        "            d.eval()\n",
        "\n",
        "            noise = torch.randn((X.size(0), g.input_size)).to(device)\n",
        "            generated_images = g(noise)\n",
        "\n",
        "            d_output = d(generated_images)\n",
        "            g_gt = torch.ones(X.size(0)).view(-1, 1).to(device)\n",
        "\n",
        "            g_optimizer.zero_grad()\n",
        "            g_l = crit(d_output, g_gt)\n",
        "            g_l.backward()\n",
        "            g_optimizer.step()\n",
        "            current_epoch_g_loss.append(g_l.item())\n",
        "\n",
        "            mb.child.comment = f'g_loss {np.mean(current_epoch_g_loss):.5f} d_loss {np.mean(current_epoch_d_loss):.5f}'\n",
        "\n",
        "        hist['g_loss'].append(np.mean(current_epoch_g_loss))\n",
        "        hist['d_loss'].append(np.mean(current_epoch_d_loss))\n",
        "\n",
        "        mb.write(f'Epoch {epoch}/{epochs} g_loss {hist[\"g_loss\"][-1]:.5f} d_loss {hist[\"d_loss\"][-1]:.5f}')\n",
        "\n",
        "\n",
        "        if epoch % save_interval == 0:\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'generator_state_dict': g.state_dict(),\n",
        "                'discriminator_state_dict': d.state_dict(),\n",
        "                'g_optimizer_state_dict': g_optimizer.state_dict(),\n",
        "                'd_optimizer_state_dict': d_optimizer.state_dict(),\n",
        "                'g_loss': hist['g_loss'],\n",
        "                'd_loss': hist['d_loss']\n",
        "            }, os.path.join(checkpoint_dir, f'GANs_modelo_{epoch}.pth'))\n",
        "\n",
        "    return hist"
      ],
      "metadata": {
        "id": "ppcsoXNfcg50"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ejecutar el entrenamiento desde el último checkpoint\n",
        "checkpoint_path = '/content/drive/MyDrive/SIS421-IA2/Laboratorios/LAB-04/GANs_modelo_25.pth'  # Cambia esto por tu último checkpoint guardado\n",
        "hist = fit(generator, discriminator, dataloader, crit=torch.nn.BCELoss(), resume_from_checkpoint=checkpoint_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 899
        },
        "id": "KNKs747McnTI",
        "outputId": "49623a8d-2214-452d-c0d8-6e10702f9d25"
      },
      "execution_count": 43,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error loading checkpoint: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n",
            "\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n",
            "\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n",
            "\tWeightsUnpickler error: Unsupported global: GLOBAL numpy._core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([numpy._core.multiarray.scalar])` or the `torch.serialization.safe_globals([numpy._core.multiarray.scalar])` context manager to allowlist this global if you trust this class/function.\n",
            "\n",
            "Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\n",
            "Starting training from scratch instead.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='5' class='' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      20.00% [5/25 04:16&lt;17:07]\n",
              "    </div>\n",
              "    \n",
              "Epoch 1/25 g_loss 4.47735 d_loss 0.13702<p>Epoch 2/25 g_loss 4.54421 d_loss 0.13446<p>Epoch 3/25 g_loss 4.57432 d_loss 0.13481<p>Epoch 4/25 g_loss 4.61532 d_loss 0.13093<p>Epoch 5/25 g_loss 4.67805 d_loss 0.12920<p>\n",
              "\n",
              "    <div>\n",
              "      <progress value='1376' class='' max='1875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      73.39% [1376/1875 00:37&lt;00:13 g_loss 4.67553 d_loss 0.12949]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Epoch 1/25 g_loss 4.47735 d_loss 0.13702<p>Epoch 2/25 g_loss 4.54421 d_loss 0.13446<p>Epoch 3/25 g_loss 4.57432 d_loss 0.13481<p>Epoch 4/25 g_loss 4.61532 d_loss 0.13093<p>Epoch 5/25 g_loss 4.67805 d_loss 0.12920<p>Epoch 6/25 g_loss 4.67005 d_loss 0.12921<p>Epoch 7/25 g_loss 4.71853 d_loss 0.12899<p>Epoch 8/25 g_loss 4.74937 d_loss 0.12570<p>Epoch 9/25 g_loss 4.78119 d_loss 0.12790<p>Epoch 10/25 g_loss 4.82394 d_loss 0.12449<p>Epoch 11/25 g_loss 4.86703 d_loss 0.12295<p>Epoch 12/25 g_loss 4.91472 d_loss 0.12325<p>Epoch 13/25 g_loss 4.93450 d_loss 0.12062<p>Epoch 14/25 g_loss 4.93534 d_loss 0.11807<p>Epoch 15/25 g_loss 4.94948 d_loss 0.12093<p>Epoch 16/25 g_loss 4.99455 d_loss 0.11870<p>Epoch 17/25 g_loss 5.05382 d_loss 0.11748<p>Epoch 18/25 g_loss 5.06726 d_loss 0.11447<p>Epoch 19/25 g_loss 5.12736 d_loss 0.11558<p>Epoch 20/25 g_loss 5.11087 d_loss 0.11405<p>Epoch 21/25 g_loss 5.18130 d_loss 0.11442<p>Epoch 22/25 g_loss 5.21416 d_loss 0.11139<p>Epoch 23/25 g_loss 5.22793 d_loss 0.11459<p>Epoch 24/25 g_loss 5.25169 d_loss 0.10880<p>Epoch 25/25 g_loss 5.30231 d_loss 0.10877"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "cSKQXY9wcf3B"
      },
      "outputs": [],
      "source": [
        " from fastprogress import master_bar, progress_bar\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def load_checkpoint(checkpoint_path, g, d, g_optimizer, d_optimizer):\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    g.load_state_dict(checkpoint['generator_state_dict'])\n",
        "    d.load_state_dict(checkpoint['discriminator_state_dict'])\n",
        "    g_optimizer.load_state_dict(checkpoint['g_optimizer_state_dict'])\n",
        "    # Corrected: Load the discriminator optimizer state dictionary\n",
        "    d_optimizer.load_state_dict(checkpoint['d_optimizer_state_dict'])\n",
        "    start_epoch = checkpoint['epoch'] + 1  # Resume from the next epoch\n",
        "    g_loss = checkpoint['g_loss']\n",
        "    d_loss = checkpoint['d_loss']\n",
        "    return start_epoch, g_loss, d_loss\n",
        "\n",
        "def fit(g, d, dataloader, epochs=25, crit=None, checkpoint_dir='/content/drive/MyDrive/SIS421-IA2/Laboratorios/LAB-04/', save_interval=5, resume_from_checkpoint=None):\n",
        "    g.to(device)\n",
        "    d.to(device)\n",
        "\n",
        "    g_optimizer = torch.optim.Adam(g.parameters(), lr=3e-4)\n",
        "    d_optimizer = torch.optim.Adam(d.parameters(), lr=3e-4)\n",
        "\n",
        "    crit = nn.BCEWithLitLoss() if crit is None else crit\n",
        "\n",
        "    # If resuming from a checkpoint, load the model, optimizers, and losses\n",
        "    if resume_from_checkpoint:\n",
        "        start_epoch, g_loss, d_loss = load_checkpoint(resume_from_checkpoint, g, d, g_optimizer, d_optimizer)\n",
        "    else:\n",
        "        start_epoch = 1\n",
        "        g_loss, d_loss = [], []\n",
        "\n",
        "    mb = master_bar(range(start_epoch, epochs+1))\n",
        "    hist = {'g_loss': [], 'd_loss': []}\n",
        "\n",
        "    # Create the checkpoint directory if it doesn't exist\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        os.makedirs(checkpoint_dir)\n",
        "\n",
        "    for epoch in mb:\n",
        "        for X, _ in progress_bar(dataloader, parent=mb):\n",
        "            X = X.to(device)  # Ensure real images go to the device\n",
        "\n",
        "            # Train the discriminator\n",
        "            g.eval()\n",
        "            d.train()\n",
        "\n",
        "            # Generate a batch of fake images\n",
        "            noise = torch.randn((X.size(0), g.input_size)).to(device)  # Noise vector\n",
        "            generated_images = g(noise)  # Generate fake images\n",
        "\n",
        "            # Concatenate real and generated images for the discriminator\n",
        "            d_input = torch.cat([generated_images, X], dim=0)\n",
        "            # Create labels: 0 for fake images and 1 for real images\n",
        "            d_gt = torch.cat([torch.zeros(X.size(0)), torch.ones(X.size(0))]).view(-1, 1).to(device)\n",
        "\n",
        "            # Optimize the discriminator\n",
        "            d_optimizer.zero_grad()\n",
        "            d_output = d(d_input)\n",
        "            d_l = crit(d_output, d_gt)\n",
        "            d_l.backward()\n",
        "            d_optimizer.step()\n",
        "            d_loss.append(d_l.item())\n",
        "\n",
        "            # Train the generator\n",
        "            g.train()\n",
        "            d.eval()\n",
        "\n",
        "            # Generate a new batch of fake images\n",
        "            noise = torch.randn((X.size(0), g.input_size)).to(device)\n",
        "            generated_images = g(noise)\n",
        "\n",
        "            # Pass the fake images through the discriminator\n",
        "            d_output = d(generated_images)\n",
        "            # Generator's goal: fool the discriminator, so we use \"real\" labels (1)\n",
        "            g_gt = torch.ones(X.size(0)).view(-1, 1).to(device)\n",
        "\n",
        "            # Optimize the generator\n",
        "            g_optimizer.zero_grad()\n",
        "            g_l = crit(d_output, g_gt)\n",
        "            g_l.backward()\n",
        "            g_optimizer.step()\n",
        "            g_loss.append(g_l.item())\n",
        "\n",
        "            # Progress logs\n",
        "            mb.child.comment = f'g_loss {np.mean(g_loss):.5f} d_loss {np.mean(d_loss):.5f}'\n",
        "        mb.write(f'Epoch {epoch}/{epochs} g_loss {np.mean(g_loss):.5f} d_loss {np.mean(d_loss):.5f}')\n",
        "        hist['g_loss'].append(np.mean(g_loss))\n",
        "        hist['d_loss'].append(np.mean(d_loss))\n",
        "\n",
        "        # Save a checkpoint every 'save_interval' epochs\n",
        "        if epoch % save_interval == 0:\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'generator_state_dict': g.state_dict(),\n",
        "                'discriminator_state_dict': d.state_dict(),\n",
        "                'g_optimizer_state_dict': g_optimizer.state_dict(),\n",
        "                'd_optimizer_state_dict': d_optimizer.state_dict(), # Corrected: Save the discriminator optimizer state dict\n",
        "                'g_loss': g_loss,\n",
        "                'd_loss': d_loss\n",
        "            }, os.path.join(checkpoint_dir, f'GANs_modelo_{epoch}.pth'))\n",
        "\n",
        "    return hist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "cIZI_aFRENWt"
      },
      "outputs": [],
      "source": [
        "def fit(g, d, dataloader, epochs=25, crit=None, checkpoint_dir='/content/drive/MyDrive/SIS421-IA2/Laboratorios/LAB-04', save_interval=5, resume_from_checkpoint=None):\n",
        "    g.to(device)\n",
        "    d.to(device)\n",
        "\n",
        "    g_optimizer = torch.optim.Adam(g.parameters(), lr=3e-4)\n",
        "    d_optimizer = torch.optim.Adam(d.parameters(), lr=3e-4)\n",
        "\n",
        "    crit = nn.BCEWithLogitsLoss() if crit is None else crit\n",
        "\n",
        "    # Si se retoma desde un checkpoint, cargar el modelo, optimizadores y pérdidas\n",
        "    if resume_from_checkpoint:\n",
        "        start_epoch, g_loss, d_loss = load_checkpoint(resume_from_checkpoint, g, d, g_optimizer, d_optimizer)\n",
        "    else:\n",
        "        start_epoch = 1\n",
        "        g_loss, d_loss = [], []\n",
        "\n",
        "    mb = master_bar(range(start_epoch, epochs+1))\n",
        "    hist = {'g_loss': [], 'd_loss': []}\n",
        "\n",
        "    # Crear el directorio de checkpoints si no existe\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        os.makedirs(checkpoint_dir)\n",
        "\n",
        "    for epoch in mb:\n",
        "        for X, _ in progress_bar(dataloader, parent=mb):\n",
        "            X = X.to(device)  # Aseguramos que las imágenes reales vayan al dispositivo\n",
        "\n",
        "            # Entrenamos el discriminador\n",
        "            g.eval()\n",
        "            d.train()\n",
        "\n",
        "            # Generamos un batch de imágenes falsas\n",
        "            noise = torch.randn((X.size(0), g.input_size)).to(device)  # Vector de ruido\n",
        "            generated_images = g(noise)  # Generamos imágenes falsas\n",
        "\n",
        "            # Concatenamos imágenes reales y generadas para el discriminador\n",
        "            d_input = torch.cat([generated_images, X], dim=0)\n",
        "            # Creamos etiquetas: 0 para imágenes falsas y 1 para reales\n",
        "            d_gt = torch.cat([torch.zeros(X.size(0)), torch.ones(X.size(0))]).view(-1, 1).to(device)\n",
        "\n",
        "            # Optimizamos el discriminador\n",
        "            d_optimizer.zero_grad()\n",
        "            d_output = d(d_input)\n",
        "            d_l = crit(d_output, d_gt)\n",
        "            d_l.backward()\n",
        "            d_optimizer.step()\n",
        "            d_loss.append(d_l.item())\n",
        "\n",
        "            # Entrenamos el generador\n",
        "            g.train()\n",
        "            d.eval()\n",
        "\n",
        "            # Generamos un nuevo batch de imágenes falsas\n",
        "            noise = torch.randn((X.size(0), g.input_size)).to(device)\n",
        "            generated_images = g(noise)\n",
        "\n",
        "            # Pasamos las imágenes falsas por el discriminador\n",
        "            d_output = d(generated_images)\n",
        "            # Objetivo del generador: engañar al discriminador, por eso usamos etiquetas de \"reales\" (1)\n",
        "            g_gt = torch.ones(X.size(0)).view(-1, 1).to(device)\n",
        "\n",
        "            # Optimizamos el generador\n",
        "            g_optimizer.zero_grad()\n",
        "            g_l = crit(d_output, g_gt)\n",
        "            g_l.backward()\n",
        "            g_optimizer.step()\n",
        "            g_loss.append(g_l.item())\n",
        "\n",
        "            # Logs de progreso\n",
        "            mb.child.comment = f'g_loss {np.mean(g_loss):.5f} d_loss {np.mean(d_loss):.5f}'\n",
        "        mb.write(f'Epoch {epoch}/{epochs} g_loss {np.mean(g_loss):.5f} d_loss {np.mean(d_loss):.5f}')\n",
        "        hist['g_loss'].append(np.mean(g_loss))\n",
        "        hist['d_loss'].append(np.mean(d_loss))\n",
        "\n",
        "        # Guardar un checkpoint cada 'save_interval' épocas\n",
        "        if epoch % save_interval == 0:\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'generator_state_dict': g.state_dict(),\n",
        "                'discriminator_state_dict': d.state_dict(),\n",
        "                'g_optimizer_state_dict': g_optimizer.state_dict(),\n",
        "                'd_optimizer_state_dict': d_optimizer.state_dict(),\n",
        "                'g_loss': g_loss,\n",
        "                'd_loss': d_loss\n",
        "            }, os.path.join(checkpoint_dir, f'GANs_modelo_{epoch}.pth'))\n",
        "\n",
        "    return hist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JES54RrJU8Vx"
      },
      "source": [
        "##EVALUACIÓN DE LOS MODELOS\n",
        "\n",
        "###Cargamos los modelos guardados para verificar el mejor medelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "Wtz7GKT9U7J7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Cargar un model dado\n",
        "def load_model(checkpoint_path, g, d, g_optimizer, d_optimizer):\n",
        "    # Added weights_only=False to allow loading of the checkpoint\n",
        "    model = torch.load(checkpoint_path, weights_only=False)\n",
        "    g.load_state_dict(model['generator_state_dict'])\n",
        "    d.load_state_dict(model['discriminator_state_dict'])\n",
        "    g_optimizer.load_state_dict(model['g_optimizer_state_dict'])\n",
        "    d_optimizer.load_state_dict(model['d_optimizer_state_dict'])\n",
        "    epoch = model['epoch']\n",
        "    g_loss = model['g_loss']\n",
        "    d_loss = model['d_loss']\n",
        "    print(f\"Checkpoint loaded from epoch {epoch}\")\n",
        "    return epoch, g_loss, d_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "gWleQc0AVfMT"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "def generate_and_plot_images(g, num_images=5):\n",
        "    g.eval()  # Evaluation mode\n",
        "    noise = torch.randn(num_images, g.input_size).to(device)\n",
        "    with torch.no_grad():\n",
        "        generated_images = g(noise).cpu()\n",
        "\n",
        "    # Show the generated images\n",
        "    fig, axs = plt.subplots(1, num_images, figsize=(num_images * 3, 3))\n",
        "    for i in range(num_images):\n",
        "        img = generated_images[i].squeeze().permute(1, 0)  # Remove channel dimension for grayscale\n",
        "        img = (img + 1) / 2  # Desnormalize if using [-1, 1]\n",
        "        axs[i].imshow(img, cmap='gray') # Use gray colormap\n",
        "        axs[i].axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSvdKX6D4thB"
      },
      "source": [
        "Cargamos los modelos para ver los mejores valores resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "BCgfm8y_Vaea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "6567d121-c775-4564-f5d5-8fb3b87f6d29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cargando y evaluando: /content/drive/MyDrive/SIS421-IA2/Laboratorios/LAB-04/GANs_modelo_20.pth\n",
            "Checkpoint loaded from epoch 20\n",
            "Evaluando el checkpoint del epoch 20: Último g_loss = 5.11087, Último d_loss = 0.11405\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x300 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cargando y evaluando: /content/drive/MyDrive/SIS421-IA2/Laboratorios/LAB-04/GANs_modelo_22.pth\n",
            "Error: El archivo /content/drive/MyDrive/SIS421-IA2/Laboratorios/LAB-04/GANs_modelo_22.pth no fue encontrado.\n",
            "\n",
            "Cargando y evaluando: /content/drive/MyDrive/SIS421-IA2/Laboratorios/LAB-04/GANs_modelo_24.pth\n",
            "Error: El archivo /content/drive/MyDrive/SIS421-IA2/Laboratorios/LAB-04/GANs_modelo_24.pth no fue encontrado.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import os # Import the os module\n",
        "\n",
        "# Asegúrate de que las definiciones de las clases Generator y Discriminator (en tus celdas anteriores)\n",
        "# se hayan ejecutado ANTES de esta celda.\n",
        "# Por ejemplo:\n",
        "# class Generator(nn.Module):\n",
        "#     ... # Tu definición aquí\n",
        "# class Discriminator(nn.Module):\n",
        "#     ... # Tu definición aquí\n",
        "\n",
        "# Inicializar el generador y discriminador\n",
        "generator = Generator().to(device) # Asegúrate de enviarlos al dispositivo\n",
        "discriminator = Discriminator().to(device) # Asegúrate de enviarlos al dispositivo\n",
        "\n",
        "# Inicializar los optimizadores\n",
        "# Aunque fit los inicializa internamente, load_model espera optimizadores ya creados\n",
        "g_optimizer = optim.Adam(generator.parameters(), lr=3e-4)\n",
        "d_optimizer = optim.Adam(discriminator.parameters(), lr=3e-4)\n",
        "\n",
        "models = [\n",
        "    '/content/drive/MyDrive/SIS421-IA2/Laboratorios/LAB-04/GANs_modelo_20.pth',\n",
        "    '/content/drive/MyDrive/SIS421-IA2/Laboratorios/LAB-04/GANs_modelo_22.pth',\n",
        "    '/content/drive/MyDrive/SIS421-IA2/Laboratorios/LAB-04/GANs_modelo_24.pth'\n",
        "]\n",
        "\n",
        "# Asegúrate de que la función load_model (celda Wtz7GKT9U7J7)\n",
        "# y generate_and_plot_images (celda gWleQc0AVfMT)\n",
        "# se hayan ejecutado ANTES de este bucle.\n",
        "\n",
        "for model in models:\n",
        "    print(f\"\\nCargando y evaluando: {model}\")\n",
        "    # Check if the model file exists before attempting to load\n",
        "    if os.path.exists(model):\n",
        "        # Asegúrate de que la función load_model esté definida y ejecutada\n",
        "        # La función load_model debe cargar el estado de los optimizadores también\n",
        "        epoch, g_loss_hist, d_loss_hist = load_model(model, generator, discriminator, g_optimizer, d_optimizer)\n",
        "\n",
        "        # Usamos las últimas pérdidas guardadas en el historial\n",
        "        print(f\"Evaluando el checkpoint del epoch {epoch}: Último g_loss = {g_loss_hist[-1]:.5f}, Último d_loss = {d_loss_hist[-1]:.5f}\")\n",
        "\n",
        "        # Asegúrate de que la función generate_and_plot_images esté definida y ejecutada\n",
        "        generate_and_plot_images(generator, num_images=5)\n",
        "    else:\n",
        "        print(f\"Error: El archivo {model} no fue encontrado.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "Gj0oKS20ZKsP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67bafb5c-c3ea-4bd9-d45a-bacddb1fb8bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint loaded from epoch 20\n",
            "Warning: El archivo /content/drive/MyDrive/SIS421-IA2/Laboratorios/LAB-04/GANs_modelo_22.pth no fue encontrado. Saltando este checkpoint.\n",
            "Warning: El archivo /content/drive/MyDrive/SIS421-IA2/Laboratorios/LAB-04/GANs_modelo_24.pth no fue encontrado. Saltando este checkpoint.\n"
          ]
        }
      ],
      "source": [
        "g_loss_total = []\n",
        "d_loss_total = []\n",
        "\n",
        "for model in models:\n",
        "    # Check if the model file exists before attempting to load\n",
        "    if os.path.exists(model):\n",
        "        epoch, g_loss, d_loss = load_model(model, generator, discriminator, g_optimizer, d_optimizer)\n",
        "        g_loss_total.extend(g_loss)  # Agregar las pérdidas del generador\n",
        "        d_loss_total.extend(d_loss)  # Agregar las pérdidas del discriminador\n",
        "    else:\n",
        "        print(f\"Warning: El archivo {model} no fue encontrado. Saltando este checkpoint.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9mPlYplvaIE"
      },
      "source": [
        "###5. Visualización de los Resultados\n",
        "Al finalizar el entrenamiento, visualizamos las imágenes generadas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "ZGsExU7Nd6cm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbafffe6-c1f6-42da-c81d-081ad5640ce1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint loaded from epoch 25\n",
            "Checkpoint del epoch 25 cargado: g_loss = 5.302313361740112, d_loss = 0.10877061065832774\n"
          ]
        }
      ],
      "source": [
        "# Ruta del modelo que deseas cargar\n",
        "model_ = '/content/drive/MyDrive/SIS421-IA2/Laboratorios/LAB-04/GANs_modelo_25.pth'\n",
        "\n",
        "# Función para cargar el modelo\n",
        "epoch, g_loss, d_loss = load_model(model_, generator, discriminator, g_optimizer, d_optimizer)\n",
        "\n",
        "# Imprimir información del modelo cargado\n",
        "print(f\"Checkpoint del epoch {epoch} cargado: g_loss = {g_loss[-1]}, d_loss = {d_loss[-1]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "JiWBC5_nvUMU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "f721e486-0a7f-4a55-b06e-e9b52378c273"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "# Put the generator in evaluation mode\n",
        "generator.eval()\n",
        "\n",
        "# Generate images without calculating gradients\n",
        "with torch.no_grad():\n",
        "    # Create random noise to generate 10 images\n",
        "    noise = torch.randn((10, generator.input_size)).to(device)\n",
        "\n",
        "    # Generate images from the noise\n",
        "    generated_images = generator(noise)\n",
        "\n",
        "    # Configure the figure to display the images\n",
        "    fig, axs = plt.subplots(2, 5, figsize=(15, 5))\n",
        "    i = 0\n",
        "\n",
        "    # Iterate through each axis and display the images\n",
        "    for ax_row in axs:\n",
        "        for ax in ax_row:\n",
        "            # Reorganize image channels for visualization (from [C, H, W] to [H, W, C] - not needed for grayscale)\n",
        "            # Squeeze to remove the single channel dimension for grayscale images\n",
        "            img = generated_images[i].squeeze().cpu()\n",
        "\n",
        "            # Rescale image values from [-1, 1] to [0, 1] for visualization\n",
        "            ax.imshow((img + 1) / 2, cmap='gray')  # Use gray colormap\n",
        "            ax.axis('off')  # Hide axes\n",
        "            i += 1\n",
        "\n",
        "    # Show the generated images\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7xwSJISfyhw"
      },
      "source": [
        "En este caso las imágenes generadas son un poco mejores que las que obteníamos con la GAN simple, aunque todavía hay márgen de mejora."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe130526"
      },
      "source": [
        "from fastprogress import master_bar, progress_bar\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def load_checkpoint(checkpoint_path, g, d, g_optimizer, d_optimizer):\n",
        "    # Added weights_only=False to allow loading of the checkpoint\n",
        "    checkpoint = torch.load(checkpoint_path, weights_only=False)\n",
        "    g.load_state_dict(checkpoint['generator_state_dict'])\n",
        "    d.load_state_dict(checkpoint['discriminator_state_dict'])\n",
        "    g_optimizer.load_state_dict(checkpoint['g_optimizer_state_dict'])\n",
        "    d_optimizer.load_state_dict(checkpoint['d_optimizer_state_dict'])\n",
        "    start_epoch = checkpoint['epoch'] + 1  # Resume from the next epoch\n",
        "    g_loss = checkpoint['g_loss']\n",
        "    d_loss = checkpoint['d_loss']\n",
        "    return start_epoch, g_loss, d_loss\n",
        "\n",
        "def fit(g, d, dataloader, epochs=25, crit=None, checkpoint_dir='/content/drive/MyDrive/SIS421-IA2/Laboratorios/LAB-04/', save_interval=5, resume_from_checkpoint=None):\n",
        "    g.to(device)\n",
        "    d.to(device)\n",
        "\n",
        "    g_optimizer = torch.optim.Adam(g.parameters(), lr=3e-4)\n",
        "    d_optimizer = torch.optim.Adam(d.parameters(), lr=3e-4)\n",
        "\n",
        "    crit = nn.BCEWithLogitsLoss() if crit is None else crit\n",
        "\n",
        "    # If resuming from a checkpoint, load the model, optimizers, and losses\n",
        "    if resume_from_checkpoint:\n",
        "        # Modified: Call the updated load_checkpoint function\n",
        "        start_epoch, g_loss, d_loss = load_checkpoint(resume_from_checkpoint, g, d, g_optimizer, d_optimizer)\n",
        "    else:\n",
        "        start_epoch = 1\n",
        "        g_loss, d_loss = [], []\n",
        "\n",
        "    mb = master_bar(range(start_epoch, epochs+1))\n",
        "    hist = {'g_loss': [], 'd_loss': []}\n",
        "\n",
        "    # Create the checkpoint directory if it doesn't exist\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        os.makedirs(checkpoint_dir)\n",
        "\n",
        "    for epoch in mb:\n",
        "        for X, _ in progress_bar(dataloader, parent=mb):\n",
        "            X = X.to(device)  # Ensure real images go to the device\n",
        "\n",
        "            # Train the discriminator\n",
        "            g.eval()\n",
        "            d.train()\n",
        "\n",
        "            # Generate a batch of fake images\n",
        "            noise = torch.randn((X.size(0), g.input_size)).to(device)  # Noise vector\n",
        "            generated_images = g(noise)  # Generate fake images\n",
        "\n",
        "            # Concatenate real and generated images for the discriminator\n",
        "            d_input = torch.cat([generated_images, X], dim=0)\n",
        "            # Create labels: 0 for fake images and 1 for real images\n",
        "            d_gt = torch.cat([torch.zeros(X.size(0)), torch.ones(X.size(0))]).view(-1, 1).to(device)\n",
        "\n",
        "            # Optimize the discriminator\n",
        "            d_optimizer.zero_grad()\n",
        "            d_output = d(d_input)\n",
        "            d_l = crit(d_output, d_gt)\n",
        "            d_l.backward()\n",
        "            d_optimizer.step()\n",
        "            d_loss.append(d_l.item())\n",
        "\n",
        "            # Train the generator\n",
        "            g.train()\n",
        "            d.eval()\n",
        "\n",
        "            # Generate a new batch of fake images\n",
        "            noise = torch.randn((X.size(0), g.input_size)).to(device)\n",
        "            generated_images = g(noise)\n",
        "\n",
        "            # Pass the fake images through the discriminator\n",
        "            d_output = d(generated_images)\n",
        "            # Generator's goal: fool the discriminator, so we use \"real\" labels (1)\n",
        "            g_gt = torch.ones(X.size(0)).view(-1, 1).to(device)\n",
        "\n",
        "            # Optimize the generator\n",
        "            g_optimizer.zero_grad()\n",
        "            g_l = crit(d_output, g_gt)\n",
        "            g_l.backward()\n",
        "            g_optimizer.step()\n",
        "            g_loss.append(g_l.item())\n",
        "\n",
        "            # Progress logs\n",
        "            mb.child.comment = f'g_loss {np.mean(g_loss):.5f} d_loss {np.mean(d_loss):.5f}'\n",
        "        mb.write(f'Epoch {epoch}/{epochs} g_loss {np.mean(g_loss):.5f} d_loss {np.mean(d_loss):.5f}')\n",
        "        hist['g_loss'].append(np.mean(g_loss))\n",
        "        hist['d_loss'].append(np.mean(d_loss))\n",
        "\n",
        "        # Save a checkpoint every 'save_interval' epochs\n",
        "        if epoch % save_interval == 0:\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'generator_state_dict': g.state_dict(),\n",
        "                'discriminator_state_dict': d.state_dict(),\n",
        "                'g_optimizer_state_dict': g_optimizer.state_dict(),\n",
        "                'd_optimizer_state_dict': d_optimizer.state_dict(),\n",
        "                'g_loss': g_loss,\n",
        "                'd_loss': d_loss\n",
        "            }, os.path.join(checkpoint_dir, f'GANs_modelo_{epoch}.pth'))\n",
        "\n",
        "    return hist"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8e84212"
      },
      "source": [
        "# Ejecutar el entrenamiento desde el último checkpoint\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "checkpoint_path = '/content/drive/MyDrive/SIS421-IA2/Laboratorios/LAB-04/GANs_modelo_25.pth'  # Cambia esto por tu último checkpoint guardado\n",
        "hist = fit(generator, discriminator, dataloader, crit=torch.nn.BCELoss(), resume_from_checkpoint=checkpoint_path)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40582094"
      },
      "source": [
        "from fastprogress import master_bar, progress_bar\n",
        "import numpy as np\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def fit(g, d, dataloader, epochs=25, crit=None, checkpoint_dir='/content/drive/MyDrive/SIS421-IA2/Laboratorios/LAB-04/', save_interval=5, resume_from_checkpoint=None):\n",
        "    g.to(device)\n",
        "    d.to(device)\n",
        "\n",
        "    g_optimizer = torch.optim.Adam(g.parameters(), lr=3e-4)\n",
        "    d_optimizer = torch.optim.Adam(d.parameters(), lr=3e-4)\n",
        "\n",
        "    crit = nn.BCEWithLogitsLoss() if crit is None else crit\n",
        "\n",
        "    # Helper function to load checkpoint (defined inside fit to ensure correct version is used)\n",
        "    def load_checkpoint(checkpoint_path, g, d, g_optimizer, d_optimizer):\n",
        "        checkpoint = torch.load(checkpoint_path)\n",
        "        g.load_state_dict(checkpoint['generator_state_dict'])\n",
        "        d.load_state_dict(checkpoint['discriminator_state_dict'])\n",
        "        g_optimizer.load_state_dict(checkpoint['g_optimizer_state_dict'])\n",
        "        d_optimizer.load_state_dict(checkpoint['d_optimizer_state_dict'])\n",
        "        start_epoch = checkpoint['epoch'] + 1  # Resume from the next epoch\n",
        "        g_loss = checkpoint['g_loss']\n",
        "        d_loss = checkpoint['d_loss']\n",
        "        return start_epoch, g_loss, d_loss\n",
        "\n",
        "    # If resuming from a checkpoint, load the model, optimizers, and losses\n",
        "    if resume_from_checkpoint:\n",
        "        start_epoch, g_loss, d_loss = load_checkpoint(resume_from_checkpoint, g, d, g_optimizer, d_optimizer)\n",
        "    else:\n",
        "        start_epoch = 1\n",
        "        g_loss, d_loss = [], []\n",
        "\n",
        "    mb = master_bar(range(start_epoch, epochs+1))\n",
        "    hist = {'g_loss': [], 'd_loss': []}\n",
        "\n",
        "    # Create the checkpoint directory if it doesn't exist\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        os.makedirs(checkpoint_dir)\n",
        "\n",
        "    for epoch in mb:\n",
        "        for X, _ in progress_bar(dataloader, parent=mb):\n",
        "            X = X.to(device)  # Ensure real images go to the device\n",
        "\n",
        "            # Train the discriminator\n",
        "            g.eval()\n",
        "            d.train()\n",
        "\n",
        "            # Generate a batch of fake images\n",
        "            noise = torch.randn((X.size(0), g.input_size)).to(device)  # Noise vector\n",
        "            generated_images = g(noise)  # Generate fake images\n",
        "\n",
        "            # Concatenate real and generated images for the discriminator\n",
        "            d_input = torch.cat([generated_images, X], dim=0)\n",
        "            # Create labels: 0 for fake images and 1 for real images\n",
        "            d_gt = torch.cat([torch.zeros(X.size(0)), torch.ones(X.size(0))]).view(-1, 1).to(device)\n",
        "\n",
        "            # Optimize the discriminator\n",
        "            d_optimizer.zero_grad()\n",
        "            d_output = d(d_input)\n",
        "            d_l = crit(d_output, d_gt)\n",
        "            d_l.backward()\n",
        "            d_optimizer.step()\n",
        "            d_loss.append(d_l.item())\n",
        "\n",
        "            # Train the generator\n",
        "            g.train()\n",
        "            d.eval()\n",
        "\n",
        "            # Generate a new batch of fake images\n",
        "            noise = torch.randn((X.size(0), g.input_size)).to(device)\n",
        "            generated_images = g(noise)\n",
        "\n",
        "            # Pass the fake images through the discriminator\n",
        "            d_output = d(generated_images)\n",
        "            # Generator's goal: fool the discriminator, so we use \"real\" labels (1)\n",
        "            g_gt = torch.ones(X.size(0)).view(-1, 1).to(device)\n",
        "\n",
        "            # Optimizamos el generador\n",
        "            g_optimizer.zero_grad()\n",
        "            g_l = crit(d_output, g_gt)\n",
        "            g_l.backward()\n",
        "            g_optimizer.step()\n",
        "            g_loss.append(g_l.item())\n",
        "\n",
        "            # Progress logs\n",
        "            mb.child.comment = f'g_loss {np.mean(g_loss):.5f} d_loss {np.mean(d_loss):.5f}'\n",
        "        mb.write(f'Epoch {epoch}/{epochs} g_loss {np.mean(g_loss):.5f} d_loss {np.mean(d_loss):.5f}')\n",
        "        hist['g_loss'].append(np.mean(g_loss))\n",
        "        hist['d_loss'].append(np.mean(d_loss))\n",
        "\n",
        "        # Save a checkpoint every 'save_interval' epochs\n",
        "        if epoch % save_interval == 0:\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'generator_state_dict': g.state_dict(),\n",
        "                'discriminator_state_dict': d.state_dict(),\n",
        "                'g_optimizer_state_dict': g_optimizer.state_dict(),\n",
        "                'd_optimizer_state_dict': d_optimizer.state_dict(),\n",
        "                'g_loss': g_loss,\n",
        "                'd_loss': d_loss\n",
        "            }, os.path.join(checkpoint_dir, f'GANs_modelo_{epoch}.pth'))\n",
        "\n",
        "    return hist"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "123bd914"
      },
      "source": [
        "# Asegúrate de tener las importaciones necesarias si no están ya en tu notebook\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import os\n",
        "from fastprogress import master_bar, progress_bar\n",
        "import matplotlib.pyplot as plt # Para visualizar resultados si es necesario\n",
        "\n",
        "# Definición del Generador (asegúrate de que esta clase ya está definida arriba en tu notebook)\n",
        "# class Generator(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "#         self.input_size = 25\n",
        "#         ... # Resto de la definición del generador\n",
        "\n",
        "# Definición del Discriminador (asegúrate de que esta clase ya está definida arriba en tu notebook)\n",
        "# class Discriminator(nn.Module):\n",
        "#     def __init__(self):\n",
        "#         super().__init__()\n",
        "#         ... # Resto de la definición del discriminador\n",
        "\n",
        "# Asegúrate de tener las instancias del generador y discriminador inicializadas\n",
        "# generator = Generator()\n",
        "# discriminator = Discriminator()\n",
        "\n",
        "# Asegúrate de tener el dataloader listo\n",
        "# dataloader = torch.utils.data.DataLoader(...)\n",
        "\n",
        "# Define el dispositivo\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def fit(g, d, dataloader, epochs=25, crit=None, checkpoint_dir='/content/drive/MyDrive/SIS421-IA2/Laboratorios/LAB-04/', save_interval=5, resume_from_checkpoint=None):\n",
        "    g.to(device)\n",
        "    d.to(device)\n",
        "\n",
        "    g_optimizer = torch.optim.Adam(g.parameters(), lr=3e-4)\n",
        "    d_optimizer = torch.optim.Adam(d.parameters(), lr=3e-4)\n",
        "\n",
        "    crit = nn.BCEWithLogitsLoss() if crit is None else crit\n",
        "\n",
        "    # Helper function to load checkpoint (defined inside fit to ensure correct version is used)\n",
        "    def load_checkpoint(checkpoint_path, g, d, g_optimizer, d_optimizer):\n",
        "        checkpoint = torch.load(checkpoint_path)\n",
        "        g.load_state_dict(checkpoint['generator_state_dict'])\n",
        "        d.load_state_dict(checkpoint['discriminator_state_dict'])\n",
        "        g_optimizer.load_state_dict(checkpoint['g_optimizer_state_dict'])\n",
        "        d_optimizer.load_state_dict(checkpoint['d_optimizer_state_dict'])\n",
        "        start_epoch = checkpoint['epoch'] + 1  # Resume from the next epoch\n",
        "        # Asegúrate de que g_loss y d_loss existan en el checkpoint antes de intentar acceder a ellos\n",
        "        g_loss = checkpoint.get('g_loss', []) # Usa .get para evitar errores si no existe\n",
        "        d_loss = checkpoint.get('d_loss', []) # Usa .get para evitar errores si no existe\n",
        "        print(f\"Checkpoint loaded from epoch {checkpoint.get('epoch', 'N/A')}\")\n",
        "        return start_epoch, g_loss, d_loss\n",
        "\n",
        "\n",
        "    # If resuming from a checkpoint, load the model, optimizers, and losses\n",
        "    if resume_from_checkpoint:\n",
        "        try:\n",
        "            start_epoch, g_loss, d_loss = load_checkpoint(resume_from_checkpoint, g, d, g_optimizer, d_optimizer)\n",
        "            print(f\"Resuming training from epoch {start_epoch}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading checkpoint: {e}\")\n",
        "            print(\"Starting training from scratch instead.\")\n",
        "            start_epoch = 1\n",
        "            g_loss, d_loss = [], []\n",
        "    else:\n",
        "        start_epoch = 1\n",
        "        g_loss, d_loss = [], []\n",
        "\n",
        "    mb = master_bar(range(start_epoch, epochs+1))\n",
        "    # Inicializa hist con las pérdidas cargadas si existen, o vacías si se inicia desde cero\n",
        "    hist = {'g_loss': g_loss, 'd_loss': d_loss}\n",
        "\n",
        "\n",
        "    # Create the checkpoint directory if it doesn't exist\n",
        "    if not os.path.exists(checkpoint_dir):\n",
        "        os.makedirs(checkpoint_dir)\n",
        "\n",
        "    for epoch in mb:\n",
        "        # Variables temporales para las pérdidas de la época actual\n",
        "        current_epoch_g_loss = []\n",
        "        current_epoch_d_loss = []\n",
        "\n",
        "        for X, _ in progress_bar(dataloader, parent=mb):\n",
        "            X = X.to(device)  # Ensure real images go to the device\n",
        "\n",
        "            # Train the discriminator\n",
        "            g.eval()\n",
        "            d.train()\n",
        "\n",
        "            # Generate a batch of fake images\n",
        "            noise = torch.randn((X.size(0), g.input_size)).to(device)  # Noise vector\n",
        "            generated_images = g(noise)  # Generate fake images\n",
        "\n",
        "            # Concatenate real and generated images for the discriminator\n",
        "            d_input = torch.cat([generated_images, X], dim=0)\n",
        "            # Create labels: 0 for fake images and 1 for real images\n",
        "            d_gt = torch.cat([torch.zeros(X.size(0)), torch.ones(X.size(0))]).view(-1, 1).to(device)\n",
        "\n",
        "            # Optimize the discriminator\n",
        "            d_optimizer.zero_grad()\n",
        "            d_output = d(d_input)\n",
        "            d_l = crit(d_output, d_gt)\n",
        "            d_l.backward()\n",
        "            d_optimizer.step()\n",
        "            current_epoch_d_loss.append(d_l.item())\n",
        "\n",
        "\n",
        "            # Train the generator\n",
        "            g.train()\n",
        "            d.eval()\n",
        "\n",
        "            # Generate a new batch of fake images\n",
        "            noise = torch.randn((X.size(0), g.input_size)).to(device)\n",
        "            generated_images = g(noise)\n",
        "\n",
        "            # Pass the fake images through the discriminator\n",
        "            d_output = d(generated_images)\n",
        "            # Generator's goal: fool the discriminator, so we use \"real\" labels (1)\n",
        "            g_gt = torch.ones(X.size(0)).view(-1, 1).to(device)\n",
        "\n",
        "            # Optimize the generator\n",
        "            g_optimizer.zero_grad()\n",
        "            g_l = crit(d_output, g_gt)\n",
        "            g_l.backward()\n",
        "            g_optimizer.step()\n",
        "            current_epoch_g_loss.append(g_l.item())\n",
        "\n",
        "\n",
        "            # Progress logs - use mean of current epoch losses\n",
        "            mb.child.comment = f'g_loss {np.mean(current_epoch_g_loss):.5f} d_loss {np.mean(current_epoch_d_loss):.5f}'\n",
        "\n",
        "        # Append the mean loss of the epoch to the historical losses\n",
        "        hist['g_loss'].append(np.mean(current_epoch_g_loss))\n",
        "        hist['d_loss'].append(np.mean(current_epoch_d_loss))\n",
        "\n",
        "        mb.write(f'Epoch {epoch}/{epochs} g_loss {hist[\"g_loss\"][-1]:.5f} d_loss {hist[\"d_loss\"][-1]:.5f}')\n",
        "\n",
        "\n",
        "        # Save a checkpoint every 'save_interval' epochs\n",
        "        if epoch % save_interval == 0:\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'generator_state_dict': g.state_dict(),\n",
        "                'discriminator_state_dict': d.state_dict(),\n",
        "                'g_optimizer_state_dict': g_optimizer.state_dict(),\n",
        "                'd_optimizer_state_dict': d_optimizer.state_dict(),\n",
        "                'g_loss': hist['g_loss'],  # Save the full history\n",
        "                'd_loss': hist['d_loss']   # Save the full history\n",
        "            }, os.path.join(checkpoint_dir, f'GANs_modelo_{epoch}.pth'))\n",
        "\n",
        "    return hist"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c39400f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "outputId": "5142ebbd-3446-4d26-c9eb-2175c374c42c"
      },
      "source": [
        "# --- Opción 1: Iniciar entrenamiento desde cero ---\n",
        "# Esta es la opción recomendada si sospechas que tu checkpoint está corrupto\n",
        "\n",
        "# Asegúrate de que generator y discriminator estén inicializados\n",
        "# generator = Generator() # Descomenta si necesitas inicializar\n",
        "# discriminator = Discriminator() # Descomenta si necesitas inicializar\n",
        "\n",
        "# Ejecutar el entrenamiento desde el principio\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "hist = fit(generator, discriminator, dataloader, crit=torch.nn.BCELoss(), epochs=25) # Elimina resume_from_checkpoint"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Epoch 1/25 g_loss 5.36479 d_loss 0.10875<p>Epoch 2/25 g_loss 5.37167 d_loss 0.10767<p>Epoch 3/25 g_loss 5.41140 d_loss 0.10487<p>Epoch 4/25 g_loss 5.46479 d_loss 0.10643<p>Epoch 5/25 g_loss 5.45419 d_loss 0.10505<p>Epoch 6/25 g_loss 5.47620 d_loss 0.10272<p>Epoch 7/25 g_loss 5.51773 d_loss 0.10178<p>Epoch 8/25 g_loss 5.54190 d_loss 0.10046<p>Epoch 9/25 g_loss 5.63470 d_loss 0.09964<p>Epoch 10/25 g_loss 5.63612 d_loss 0.09978<p>Epoch 11/25 g_loss 5.64757 d_loss 0.09773<p>Epoch 12/25 g_loss 5.69045 d_loss 0.09952<p>Epoch 13/25 g_loss 5.72273 d_loss 0.09611<p>Epoch 14/25 g_loss 5.70425 d_loss 0.09938<p>Epoch 15/25 g_loss 5.77381 d_loss 0.09682<p>Epoch 16/25 g_loss 5.77832 d_loss 0.09477<p>Epoch 17/25 g_loss 5.78631 d_loss 0.09486<p>Epoch 18/25 g_loss 5.85510 d_loss 0.09385<p>Epoch 19/25 g_loss 5.84485 d_loss 0.09417<p>Epoch 20/25 g_loss 5.84515 d_loss 0.09534<p>Epoch 21/25 g_loss 5.91019 d_loss 0.09339<p>Epoch 22/25 g_loss 5.88599 d_loss 0.09267<p>Epoch 23/25 g_loss 5.93758 d_loss 0.09196<p>Epoch 24/25 g_loss 5.92540 d_loss 0.08978<p>Epoch 25/25 g_loss 5.97262 d_loss 0.09217"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}