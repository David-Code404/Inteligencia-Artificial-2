{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gU-BjSKDAE9z"
      },
      "source": [
        "#**LABORATORIO 2 - MLP PYTORCH**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNa7wCj2AIPg"
      },
      "source": [
        "Nombre: Quispe Sucullani Jose David\n",
        "\n",
        "Enlace de GitHub:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM6QUwvPAMzX"
      },
      "source": [
        "##*LABORATORIO 1*\n",
        "\n",
        "###Construir un MLP, con pytorch, considerando lo siguiente:\n",
        "\n",
        "- El MLP, debe servir para realizar clasificaciones de al menos 5 clases o tipos de difentes ambitos.\n",
        "\n",
        "- El MLP debe contener al menos 50 unidades  neuronales en una capa oculta.\n",
        "\n",
        "- Se debe entrenar por almenos 1000 epochs y explicar que sucede en este proceso.\n",
        "\n",
        "- Se debe implementar un mecanismo de checkpoints para el proceso de entrenamiento que permita respaldar los valores calculados para los parametros, cada 20 epochs.\n",
        "\n",
        "- Aplicar las formas (frameworks) de exportación de modelos Torchscript y ONNX, a traves de ejemplos.\n",
        "\n",
        "- Utilizar de manera obligatoria objetos dataset y dataloader en la implementacion.\n",
        "\n",
        "- Se debe aplicar las tecnicas de normalizacion, optimizacion y buenas practicas para lograr el menor valor de costo y el mayor valor de precision.\n",
        "\n",
        "\n",
        "Se debe subir todo a un repositorio el cual debes ser compartido, ademas de subir todos los cuadernillos o codigo fuente generados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BO1FmWSF-zV7"
      },
      "outputs": [],
      "source": [
        "# IMPORTAMOS LAS LIBRERIAS\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import random\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm import tqdm  # Importar tqdm para la barra de progreso\n",
        "from torch.cuda.amp import autocast, GradScaler  # Para mixed precision training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mRunning cells with 'Python 3.12.3' requires the ipykernel package.\n",
            "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
            "\u001b[1;31mOr install 'ipykernel' using the command: '/usr/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Verifica si CUDA está disponible\n",
        "print(f\"¿CUDA disponible?: {torch.cuda.is_available()}\")\n",
        "\n",
        "# Nombre de la GPU\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"Nombre de la GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Versión de CUDA: {torch.version.cuda}\")\n",
        "else:\n",
        "    print(\"¡No se detectó CUDA! Revisa la instalación de drivers y PyTorch.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "427Uk4OeeYv5",
        "outputId": "d202080c-2ab6-4fa3-aedb-3e426da5583c"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHdIWKzchukn"
      },
      "source": [
        "#**1: Lectura del Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OetRo1d8gglY"
      },
      "source": [
        "Transformaciones: Redimensionamos los imagenes a 128x128 píxeles para convierten en tensores. La normalización se realiza para que los valores de píxeles estén en un rango adecuado para el entrenamiento del modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLMGUBXKfHbn",
        "outputId": "a8b5b909-7774-4363-8118-96e8f746bfcd"
      },
      "outputs": [],
      "source": [
        "# Definir las transformaciones para las imágenes\n",
        "from torchvision import datasets, transforms\n",
        "import torch.utils.data\n",
        "\n",
        "# Definir las transformaciones para el conjunto de datos\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((50, 50)),  # Redimensionar las imágenes a 50x50 píxeles\n",
        "    transforms.ToTensor(),  # Convertir las imágenes a tensores\n",
        "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])  # Normalización de las imágenes\n",
        "])\n",
        "\n",
        "train_data = datasets.ImageFolder(\n",
        "    root='/content/drive/MyDrive/Inteligencia-Artificial_2/Laboratorios/Laboratorio1MLP/train',\n",
        "    transform=transform\n",
        ")\n",
        "test_data = datasets.ImageFolder(\n",
        "    root='/content/drive/MyDrive/Inteligencia-Artificial_2/Laboratorios/Laboratorio1MLP/test',\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "print(f\"Número de imágenes de entrenamiento: {len(train_data)}\")\n",
        "print(f\"Número de imágenes de prueba: {len(test_data)}\")\n",
        "print(f\"Clases detectadas: {train_data.classes}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vVVPpRsPSuP1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets, transforms\n",
        "import random\n",
        "\n",
        "# Definir las transformaciones para el conjunto de datos\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((50, 50)),  # Redimensionar las imágenes a 50x50 píxeles\n",
        "    transforms.ToTensor(),  # Convertir las imágenes a tensores\n",
        "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])  # Normalización de las imágenes\n",
        "])\n",
        "\n",
        "# Función para limitar el número de archivos de cada subcarpeta\n",
        "def limit_dataset_size(root_dir, max_per_class=6000):\n",
        "    # Diccionario para almacenar rutas de las imágenes seleccionadas por clase\n",
        "    limited_dataset = []\n",
        "\n",
        "    # Iteramos por las subcarpetas en root_dir (cada subcarpeta es una clase)\n",
        "    for class_name in os.listdir(root_dir):\n",
        "        class_dir = os.path.join(root_dir, class_name)\n",
        "        if os.path.isdir(class_dir):\n",
        "            # Obtenemos todas las imágenes en la subcarpeta\n",
        "            all_images = os.listdir(class_dir)\n",
        "            # Filtramos para obtener solo imágenes, excluyendo otros tipos de archivos\n",
        "            all_images = [os.path.join(class_name, img) for img in all_images if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "            # Seleccionamos aleatoriamente 6000 imágenes\n",
        "            selected_images = random.sample(all_images, min(len(all_images), max_per_class))\n",
        "            limited_dataset.extend(selected_images)\n",
        "\n",
        "    return limited_dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntbimDpIS18M",
        "outputId": "d08e5a28-36e9-4205-e46f-45e090587a87"
      },
      "outputs": [],
      "source": [
        "# Definir la ruta del dataset\n",
        "root_dir = '/content/drive/MyDrive/Inteligencia-Artificial_2/Laboratorios/Laboratorio1MLP/train'\n",
        "\n",
        "# Obtener una lista de las rutas de imágenes limitadas a 6000 por clase\n",
        "limited_image_paths = limit_dataset_size(root_dir, max_per_class=6000)\n",
        "\n",
        "# Clase personalizada para cargar solo las imágenes seleccionadas\n",
        "class CustomImageFolder(datasets.ImageFolder):\n",
        "    def __init__(self, root, selected_files, transform=None):\n",
        "        super(CustomImageFolder, self).__init__(root, transform=transform)\n",
        "        # Filtrar el dataset para cargar solo las imágenes seleccionadas\n",
        "        self.samples = [(os.path.join(root, img), self.class_to_idx[img.split('/')[0]]) for img in selected_files]\n",
        "        self.targets = [s[1] for s in self.samples]  # Extraer las etiquetas\n",
        "\n",
        "# Crear el dataset personalizado usando solo las imágenes seleccionadas\n",
        "train_data = CustomImageFolder(root=root_dir, selected_files=limited_image_paths, transform=transform)\n",
        "\n",
        "# Verificar el número de imágenes en el nuevo conjunto de entrenamiento\n",
        "print(f\"Número total de imágenes en el nuevo conjunto de entrenamiento: {len(train_data)}\")\n",
        "\n",
        "# Verificar el número de imágenes por clase\n",
        "from collections import Counter\n",
        "print(\"Distribución de imágenes por clase:\", Counter(train_data.targets))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MIHXXjER6vTB",
        "outputId": "5fd013a4-4807-4481-bebf-ed4a7f48a872"
      },
      "outputs": [],
      "source": [
        "# 1. Ver las etiquetas del dataset (clases):\n",
        "# Ver las clases del dataset (etiquetas)\n",
        "print(f\"Clases en el conjunto de entrenamiento: {train_data.classes}\")\n",
        "print(f\"Cantidad de clases: {len(train_data.classes)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_1J_AloUMa0",
        "outputId": "117892a2-f2a5-4498-a4a1-cd055999449d"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from collections import Counter\n",
        "\n",
        "# Verificar el número total de imágenes en el conjunto de entrenamiento\n",
        "num_total_images = len(train_data)\n",
        "print(f\"Número total de imágenes en el conjunto de entrenamiento: {num_total_images}\")\n",
        "\n",
        "# Verificar el número de clases (etiquetas)\n",
        "num_classes = len(train_data.classes)\n",
        "print(f\"Número de clases: {num_classes}\")\n",
        "\n",
        "# Obtener las etiquetas de todas las imágenes (train_data.targets tiene las etiquetas de cada imagen)\n",
        "class_distribution = Counter(train_data.targets)\n",
        "\n",
        "# Mostrar cuántas imágenes hay por clase\n",
        "for class_idx, count in class_distribution.items():\n",
        "    print(f\"Clase '{train_data.classes[class_idx]}' tiene {count} imágenes\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "PSF5TuAu64Pw",
        "outputId": "619aa749-a2d1-436c-a47d-0b8391fe4482"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torchvision\n",
        "\n",
        "# Función para mostrar imágenes\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # Desnormalizar la imagen\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "# Mostrar algunas imágenes del conjunto de entrenamiento\n",
        "dataiter = iter(train_data)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# Mostrar las imágenes\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "\n",
        "# Mostrar las etiquetas correspondientes\n",
        "# Check if labels is an integer and convert it to a list if necessary\n",
        "if isinstance(labels, int):\n",
        "    labels = [labels]\n",
        "\n",
        "print('Etiquetas:', ' '.join(f'{train_data.classes[labels[j]]}' for j in range(len(labels))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHsUUsogG4lD",
        "outputId": "f97d1c33-f893-4f71-ebc3-623c0e248bf1"
      },
      "outputs": [],
      "source": [
        "# Preparar los DataLoaders en formato de diccionario\n",
        "dataloader = {\n",
        "    'train': torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True, pin_memory=True),\n",
        "    'test': torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=False, pin_memory=True)\n",
        "}\n",
        "\n",
        "# Mostrar la cantidad de imágenes de entrenamiento y prueba\n",
        "print(f\"Número de imágenes de entrenamiento: {len(train_data)}\")\n",
        "print(f\"Número de imágenes de prueba: {len(test_data)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_8ihRgn74Pt",
        "outputId": "69411195-5c57-4bde-b308-5e88580050f9"
      },
      "outputs": [],
      "source": [
        "# Obtener un lote de imágenes y etiquetas del DataLoader de entrenamiento\n",
        "images, labels = next(iter(dataloader['train']))\n",
        "\n",
        "# Mostrar el tamaño del lote de imágenes y etiquetas\n",
        "print(f\"Tamaño del lote de imágenes: {images.shape}\")  # Dimensiones del tensor de imágenes\n",
        "print(f\"Tamaño del lote de etiquetas: {labels.shape}\")  # Dimensiones del tensor de etiquetas\n",
        "\n",
        "# Ver la primera etiqueta en el lote y su correspondencia con la clase\n",
        "print(f\"Primera etiqueta en el lote: {labels[0].item()}\")  # Mostrar el valor de la primera etiqueta\n",
        "print(f\"Clase correspondiente: {train_data.classes[labels[0]]}\")  # Mostrar la clase asociada"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMF3OmtFHRIr"
      },
      "source": [
        "Aplicamos la utilización de los objetos de dataset y DataLoader para poder facilitar los dataset de grandes magnitudes dividiendo en lotes de batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "p6VRAyasigqf",
        "outputId": "cc203964-8963-455d-a04a-a7dd6d6b3101"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Obtener las clases del dataset\n",
        "classes = train_data.classes\n",
        "\n",
        "# Convertir las imágenes y etiquetas a arrays numpy para facilitar el procesamiento\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # Desnormalizar\n",
        "    npimg = img.numpy()\n",
        "    return np.transpose(npimg, (1, 2, 0))\n",
        "\n",
        "# Mostrar 10 imágenes aleatorias\n",
        "plt.figure(figsize=(10, 5))\n",
        "for i in range(10):\n",
        "    plt.subplot(2, 5, i + 1)\n",
        "    index = random.randint(0, len(train_data) - 1)\n",
        "    img, label = train_data[index]\n",
        "    plt.imshow(imshow(img))\n",
        "    plt.title(classes[label])\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCdElAWwks8w"
      },
      "source": [
        "#**2: Construcción del Modelo MLP**\n",
        "\n",
        "Ahora realizaremos la arquitectura del MLP, asegurando que cumpla con las especificaciones: al menos 50 unidades neuronales en una capa oculta y una capa de salida con 5 unidades, una para cada clase de planta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6R5NWDHXkhcj"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Definir un bloque secuencial de capas fully connected con activación y dropout\n",
        "def fc_block(input_size, output_size, dropout_rate=0.5):\n",
        "    return nn.Sequential(\n",
        "        nn.Linear(input_size, output_size),  # Capa totalmente conectada (fully connected)\n",
        "        nn.ReLU(),                           # Activación ReLU\n",
        "        nn.Dropout(dropout_rate)             # Dropout para regularización\n",
        "    )\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size=50*50*3, n_classes=5):\n",
        "        super(MLP, self).__init__()\n",
        "        # Definir las capas fully connected utilizando bloques\n",
        "        self.fc1 = fc_block(input_size, 50, dropout_rate=0.5)  # Capa de entrada con 7500 unidades y 50 neuronas\n",
        "        self.fc2 = fc_block(50, 30, dropout_rate=0.5)         # Capa oculta con 30 unidades de neuronas\n",
        "        self.fc3 = nn.Linear(30, n_classes)                    # Capa de salida con 5 clases (una por cada planta)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 50 * 50 * 3)  # Aplanar las imágenes\n",
        "        x = self.fc1(x)              # Pasar a través del primer bloque fully connected\n",
        "        x = self.fc2(x)              # Pasar a través del segundo bloque fully connected\n",
        "        x = self.fc3(x)              # Pasar a través de la capa de salida\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aP7J8ilEnHtx",
        "outputId": "5757d98c-bb71-45af-bca7-74c06b90280e"
      },
      "outputs": [],
      "source": [
        "# Configuración del dispositivo (GPU si está disponible)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alth8VJHnmLI"
      },
      "source": [
        "#**3: Configuración del Entrenamiento**\n",
        "\n",
        "Entrenaremos el modelo durante 100 epochs, implementando un mecanismo de checkpoints para guardar el modelo cada 20 epochs. Además, aplicaremos técnicas de optimización y buenas prácticas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odr9jqSrwQ9q",
        "outputId": "cf0c9cd0-a4cf-44e0-a12e-362ee2e51503"
      },
      "outputs": [],
      "source": [
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBTsv8FsBIeB"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Ruta donde se guardarán los checkpoints\n",
        "checkpoint_dir = \"/content/drive/MyDrive/Inteligencia-Artificial_2/Laboratorios/Laboratorio1MLP\"\n",
        "\n",
        "# Función para guardar un checkpoint en la ruta especificada\n",
        "def save_checkpoint(epoch, model, optimizer, loss, filename='checkpoint.pth'):\n",
        "    checkpoint = {\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'loss': loss\n",
        "    }\n",
        "    full_path = checkpoint_dir + filename  # Construir la ruta completa\n",
        "    torch.save(checkpoint, full_path)\n",
        "    print(f'Checkpoint guardado en: {full_path}')\n",
        "\n",
        "\n",
        "\n",
        "# Función para cargar un checkpoint desde la ruta especificada\n",
        "def load_checkpoint(filename, model, optimizer):\n",
        "    full_path = checkpoint_dir + filename  # Construir la ruta completa\n",
        "    checkpoint = torch.load(full_path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    epoch = checkpoint['epoch']\n",
        "    loss = checkpoint['loss']\n",
        "    print(f'Checkpoint cargado desde epoch {epoch} con pérdida {loss:.4f}')\n",
        "    return epoch, loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93GicxyIrN53"
      },
      "source": [
        "Entrenamiento desde cero y guardado de checkpoints:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HywMhVE0nM9W"
      },
      "outputs": [],
      "source": [
        "# Función para entrenar el modelo y guardar checkpoints automáticamente\n",
        "def fit_train(model, dataloader, epochs=10, lr=1e-3, checkpoint_interval=5):\n",
        "    model.to(device)  # Mover el modelo al dispositivo (CPU o GPU)\n",
        "\n",
        "    # Optimizador Adam y función de pérdida CrossEntropy\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        # Inicializar listas para pérdidas y precisiones del entrenamiento\n",
        "        model.train()\n",
        "        train_loss, train_acc = [], []\n",
        "\n",
        "        # Barras de progreso para los datos de entrenamiento\n",
        "        bar = tqdm(dataloader['train'], desc=f\"Epoch {epoch}/{epochs} - Training\")\n",
        "\n",
        "        for batch in bar:\n",
        "            X, y = batch\n",
        "            X, y = X.to(device), y.to(device)  # Mover los datos al dispositivo\n",
        "\n",
        "            # Reiniciar gradientes\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass (propagación hacia adelante)\n",
        "            y_hat = model(X)\n",
        "\n",
        "            # Cálculo de la pérdida\n",
        "            loss = criterion(y_hat, y)\n",
        "\n",
        "            # Backward pass (retropropagación) y actualización del optimizador\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Guardar el valor de la pérdida\n",
        "            train_loss.append(loss.item())\n",
        "\n",
        "            # Cálculo de precisión\n",
        "            acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n",
        "            train_acc.append(acc)\n",
        "\n",
        "            # Actualización de la barra de progreso\n",
        "            bar.set_description(f\"loss {np.mean(train_loss):.5f} acc {np.mean(train_acc):.5f}\")\n",
        "\n",
        "        # Validación del modelo después de cada época\n",
        "        model.eval()  # Cambiar a modo de evaluación\n",
        "        val_loss, val_acc = [], []\n",
        "\n",
        "        with torch.no_grad():  # Desactivar el cálculo del gradiente\n",
        "            bar = tqdm(dataloader['test'], desc=f\"Epoch {epoch}/{epochs} - Validation\")\n",
        "\n",
        "            for batch in bar:\n",
        "                X, y = batch\n",
        "                X, y = X.to(device), y.to(device)\n",
        "\n",
        "                # Forward pass en modo evaluación\n",
        "                y_hat = model(X)\n",
        "\n",
        "                # Cálculo de la pérdida de validación\n",
        "                loss = criterion(y_hat, y)\n",
        "                val_loss.append(loss.item())\n",
        "\n",
        "                # Cálculo de la precisión de validación\n",
        "                acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n",
        "                val_acc.append(acc)\n",
        "\n",
        "                # Actualización de la barra de progreso\n",
        "                bar.set_description(f\"val_loss {np.mean(val_loss):.5f} val_acc {np.mean(val_acc):.5f}\")\n",
        "\n",
        "        # Mostrar métricas al final de la época\n",
        "        print(f\"Epoch {epoch}/{epochs} - Train loss: {np.mean(train_loss):.5f} - Validation loss: {np.mean(val_loss):.5f} - Train acc: {np.mean(train_acc):.5f} - Validation acc: {np.mean(val_acc):.5f}\")\n",
        "\n",
        "        # Guardar checkpoint cada cierto número de epochs\n",
        "        if epoch % checkpoint_interval == 0:\n",
        "            save_checkpoint(epoch, model, optimizer, np.mean(train_loss), filename=f'MLP_checkpoint_epoch_{epoch}.pth')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FV95yP0X9aW5",
        "outputId": "7ccd5564-241a-4972-a055-179770a78fc0"
      },
      "outputs": [],
      "source": [
        "# Crear instancia del modelo MLP y entrenar desde cero\n",
        "model = MLP()\n",
        "fit_train(model, dataloader, epochs=10, lr=1e-3, checkpoint_interval=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9phY6kH2rT3p"
      },
      "source": [
        "Cargar un modelo desde un checkpoint y continuar el entrenamiento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJjIcWJTrb73"
      },
      "outputs": [],
      "source": [
        "# Función para continuar el entrenamiento desde un checkpoint\n",
        "def fit_train_continue(model, dataloader, checkpoint_filename, epochs=10, lr=1e-3, checkpoint_interval=5):\n",
        "    model.to(device)  # Mover el modelo al dispositivo (CPU o GPU)\n",
        "\n",
        "    # Optimizador Adam y función de pérdida CrossEntropy\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    # Cargar el checkpoint\n",
        "    start_epoch, _ = load_checkpoint(checkpoint_filename, model, optimizer)\n",
        "\n",
        "    for epoch in range(start_epoch + 1, epochs + 1):\n",
        "        # Inicializar listas para pérdidas y precisiones del entrenamiento\n",
        "        model.train()\n",
        "        train_loss, train_acc = [], []\n",
        "\n",
        "        # Barras de progreso para los datos de entrenamiento\n",
        "        bar = tqdm(dataloader['train'], desc=f\"Epoch {epoch}/{epochs} - Training\")\n",
        "\n",
        "        for batch in bar:\n",
        "            X, y = batch\n",
        "            X, y = X.to(device), y.to(device)  # Mover los datos al dispositivo\n",
        "\n",
        "            # Reiniciar gradientes\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass (propagación hacia adelante)\n",
        "            y_hat = model(X)\n",
        "\n",
        "            # Cálculo de la pérdida\n",
        "            loss = criterion(y_hat, y)\n",
        "\n",
        "            # Backward pass (retropropagación) y actualización del optimizador\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Guardar el valor de la pérdida\n",
        "            train_loss.append(loss.item())\n",
        "\n",
        "            # Cálculo de precisión\n",
        "            acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n",
        "            train_acc.append(acc)\n",
        "\n",
        "            # Actualización de la barra de progreso\n",
        "            bar.set_description(f\"loss {np.mean(train_loss):.5f} acc {np.mean(train_acc):.5f}\")\n",
        "\n",
        "        # Guardar checkpoint cada cierto número de epochs\n",
        "        if epoch % checkpoint_interval == 0:\n",
        "            save_checkpoint(epoch, model, optimizer, np.mean(train_loss), filename=f'MLP_checkpoint_epoch_{epoch}.pth')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSKw1gnJBlOp"
      },
      "source": [
        "##Evalucion del Modelo MLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wqHDWwGJsnlQ"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, dataloader):\n",
        "    model.eval()  # Establecer el modelo en modo de evaluación\n",
        "    model.to(device)  # Mover el modelo al dispositivo adecuado (CPU/GPU)\n",
        "\n",
        "    bar = tqdm(dataloader['test'], desc=\"Evaluating\")  # Barra de progreso para la evaluación\n",
        "    accuracy = []  # Lista para almacenar las precisiones\n",
        "\n",
        "    with torch.no_grad():  # Desactivar el cálculo de gradientes\n",
        "        for batch in bar:\n",
        "            X, y = batch  # Obtener las entradas (X) y etiquetas (y) del lote\n",
        "            X, y = X.to(device), y.to(device)  # Mover los datos al dispositivo\n",
        "\n",
        "            # Realizar una predicción con el modelo\n",
        "            y_hat = model(X)\n",
        "\n",
        "            # Calcular la precisión\n",
        "            acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n",
        "            accuracy.append(acc)\n",
        "\n",
        "            # Actualizar la barra de progreso con la precisión promedio actual\n",
        "            bar.set_description(f\"acc {np.mean(accuracy):.5f}\")\n",
        "\n",
        "    # Imprimir la precisión final de la evaluación\n",
        "    print(f\"Evaluación completada - Precisión promedio: {np.mean(accuracy):.5f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9U_c1ihJ-Ehw",
        "outputId": "6b34d833-f7a1-40c8-95bb-74de26056e9e"
      },
      "outputs": [],
      "source": [
        "# Evaluar el modelo MLP\n",
        "evaluate(model, dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xsylct5np_uQ",
        "outputId": "1b9ca41c-b31e-4527-8bd4-a8b3973110d8"
      },
      "outputs": [],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrtQN6uptthl"
      },
      "source": [
        "#CONCLUSIÓN Y RESULTADOS\n",
        "\n",
        "- **HiperParámetros**: Los hiperparámetros que se utilizaron fueron el valor de alpha coeficiente de aprendizaje de 0.001.\n",
        "\n",
        "Para el modelo del MLP utilizamos 128*128*3 de entrada, un 50 capas ocultas y la última capa de salida que es de 5 clases diferentes.\n",
        "\n",
        "\n",
        "Sobre los resultamos aún no se especificó los resultados correctos ya que se hacen muchas pruebas con diferentes tipos de hiperparámetros por lo que tendremos que entrenar muchas veces para sacar el mejor resultado.\n",
        "\n",
        "####Tecnicas y Prácticas\n",
        "\n",
        "- Regularización: Se añadió Dropout en el modelo para reducir el sobreajuste al apagar aleatoriamente un porcentaje de neuronas durante el entrenamiento.\n",
        "\n",
        "- Optimización: Para la optimización del modelo aplicamos un optimizador que es el Adan que adapta las tasas de aprendizaje y estabiliza el entrenamiento. Existen otros que podriamos utilizar como Learning Rate Scheduling o Gradient Clipping, pero la más famosa que se utiliza es el Adan por lo cual percatamos a utilizar para la optimización del entrenamiento.\n",
        "\n",
        "- Buenas Prácticas:\n",
        "\n",
        "  . Utilizamos DataLoader para manejar el batching y aleatorización de los datos de entrenamiento y prueba\n",
        "  \n",
        "  . Checkpoints: Guardamos el estado del modelo y el optimizador cada 20 epochs para recuperar el progreso en caso de interrupciones.\n",
        "\n",
        "  . Exportación del Modelo: Exportamos el modelo en dos\n",
        "  formatos: TorchScript para su uso en producción y ONNX para interoperabilidad con otras plataformas.\n",
        "\n",
        "\n",
        "####Entrenamiento y Evaluación\n",
        "\n",
        "- Entrenamiento: El modelo se entrena durante 1000 epochs, donde en cada epoch se realiza el forward pass, cálculo de pérdida, retropropagación y actualización de pesos. La pérdida se imprime al final de cada epoch.\n",
        "\n",
        "- Evaluación: Después del entrenamiento de cada epoch, se evalúa el modelo en el conjunto de prueba para calcular la precisión y verificar el rendimiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UEiheNpqtwC6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
