{"cells":[{"cell_type":"markdown","metadata":{"id":"peHQ1ru9MmPI"},"source":["#**LAB-02 REDES CONVOLUCIONALES TRANSFER LEARNING**\n","\n","##Nombre: Quispe Sucullani Jose David\n","##CU: 111-376\n","##Dirección de GitHub:"]},{"cell_type":"markdown","metadata":{"id":"MI8jLBNZMrfz"},"source":["##CONTEXTO DEL LABORATORIO\n","\n","Elaborar:\n","\n","2.Realizar lo solicitado en el punto 1, pero utilizando un modelo preentrenado y aplicando técnicas de transfer learning y fine tunning. El modelo preentrenado no debe tener una antiguedad mayor a 5 años.\n","\n","Se debe elaborar un informe en relación a los resultados que se obtengan en cada parte del trabajo.\n","\n","El cuadernillo a presentar solo debe tener información que el estudiante considere necesaria.\n","\n","Se debe subir el cuadernillo a ecampus y a su repositorio, para lo cual se debe incluir la dirección del mismo."]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":6959,"status":"ok","timestamp":1755748084527,"user":{"displayName":"Josè Davìd Quispe Sucullani","userId":"13586411122360630394"},"user_tz":240},"id":"1yyIXJI4MhSz"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader\n","from torchvision import models, transforms\n","from tqdm import tqdm"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22657,"status":"ok","timestamp":1755748107212,"user":{"displayName":"Josè Davìd Quispe Sucullani","userId":"13586411122360630394"},"user_tz":240},"id":"YIc8k3rLNkQj","outputId":"36e1ce10-4f8c-4369-8b02-9be02cb4e8c2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1755748107257,"user":{"displayName":"Josè Davìd Quispe Sucullani","userId":"13586411122360630394"},"user_tz":240},"id":"Jk_yoBtiNl8T","outputId":"d36975fc-69bb-425d-b192-6c2620c1f87f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cpu\n"]}],"source":["# Comprobar si hay GPU disponible\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")"]},{"cell_type":"markdown","metadata":{"id":"2rBM1hmsNot8"},"source":["#1. Preparación del Dataset"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1755748107289,"user":{"displayName":"Josè Davìd Quispe Sucullani","userId":"13586411122360630394"},"user_tz":240},"id":"iWGEIGVSSy-j"},"outputs":[],"source":["# Definir las transformaciones para las imágenes\n","transformaciones = transforms.Compose([\n","    transforms.Resize((224, 224)),  # Redimensionar las imágenes a 224x224 píxeles\n","    transforms.ToTensor(),  # Convertir las imágenes a tensores\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalizar usando los valores de los modelos preentrenados\n","])"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12521,"status":"ok","timestamp":1755748119818,"user":{"displayName":"Josè Davìd Quispe Sucullani","userId":"13586411122360630394"},"user_tz":240},"id":"pAqKM6BxNoWL","outputId":"b7f2c452-e5bb-4cd7-fad9-cb0a1f46fcf0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Número de ejemplos en el conjunto de entrenamiento: 4015\n","Número de ejemplos en el conjunto de prueba: 4009\n"]}],"source":["# CARGAR LOS DATASET\n","\n","# CARGAMOS LOS DATASET DE ENTRENAMIENTO Y PRUEBA\n","\n","import torch\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.datasets import ImageFolder\n","import os\n","\n","\n","# Cargar datasets\n","train_dir = '/content/drive/MyDrive/Inteligencia-Artificial_2/Laboratorios/Laboratorio_2/Dataset/train'\n","test_dir = '/content/drive/MyDrive/Inteligencia-Artificial_2/Laboratorios/Laboratorio_2/Dataset/test'\n","\n","trainset = ImageFolder(train_dir, transform=transformaciones)\n","testset = ImageFolder(test_dir, transform=transformaciones)\n","\n","\n","print(\"Número de ejemplos en el conjunto de entrenamiento:\", len(trainset))\n","print(\"Número de ejemplos en el conjunto de prueba:\", len(testset))"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1755748119846,"user":{"displayName":"Josè Davìd Quispe Sucullani","userId":"13586411122360630394"},"user_tz":240},"id":"NGqDXxHWTLak","outputId":"bfa40dcf-1e35-45ab-a6d4-de8d4ba50901"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n"]}],"source":["trainloader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=4)\n","testloader = DataLoader(testset, batch_size=64, shuffle=False, num_workers=4)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8715,"status":"ok","timestamp":1755748128581,"user":{"displayName":"Josè Davìd Quispe Sucullani","userId":"13586411122360630394"},"user_tz":240},"id":"uLsYcUlQxE-y","outputId":"1c9ad5f4-fd1f-46fe-f9ff-9d7ab8150b59"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (1.0.19)\n","Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from timm) (2.8.0+cu126)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from timm) (0.23.0+cu126)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm) (6.0.2)\n","Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm) (0.34.4)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm) (0.6.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub-\u003etimm) (3.19.1)\n","Requirement already satisfied: fsspec\u003e=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub-\u003etimm) (2025.3.0)\n","Requirement already satisfied: packaging\u003e=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub-\u003etimm) (25.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub-\u003etimm) (2.32.4)\n","Requirement already satisfied: tqdm\u003e=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub-\u003etimm) (4.67.1)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub-\u003etimm) (4.14.1)\n","Requirement already satisfied: hf-xet\u003c2.0.0,\u003e=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub-\u003etimm) (1.1.7)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch-\u003etimm) (75.2.0)\n","Requirement already satisfied: sympy\u003e=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch-\u003etimm) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch-\u003etimm) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-\u003etimm) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch-\u003etimm) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch-\u003etimm) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch-\u003etimm) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch-\u003etimm) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch-\u003etimm) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch-\u003etimm) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch-\u003etimm) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch-\u003etimm) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch-\u003etimm) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch-\u003etimm) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch-\u003etimm) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch-\u003etimm) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch-\u003etimm) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch-\u003etimm) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch-\u003etimm) (3.4.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision-\u003etimm) (2.0.2)\n","Requirement already satisfied: pillow!=8.3.*,\u003e=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision-\u003etimm) (11.3.0)\n","Requirement already satisfied: mpmath\u003c1.4,\u003e=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy\u003e=1.13.3-\u003etorch-\u003etimm) (1.3.0)\n","Requirement already satisfied: MarkupSafe\u003e=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2-\u003etorch-\u003etimm) (3.0.2)\n","Requirement already satisfied: charset_normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.12/dist-packages (from requests-\u003ehuggingface_hub-\u003etimm) (3.4.3)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.12/dist-packages (from requests-\u003ehuggingface_hub-\u003etimm) (3.10)\n","Requirement already satisfied: urllib3\u003c3,\u003e=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests-\u003ehuggingface_hub-\u003etimm) (2.5.0)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests-\u003ehuggingface_hub-\u003etimm) (2025.8.3)\n"]}],"source":["!pip install timm # install the missing module"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":8397,"status":"ok","timestamp":1755748136995,"user":{"displayName":"Josè Davìd Quispe Sucullani","userId":"13586411122360630394"},"user_tz":240},"id":"sckmILBnVFIs"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import timm\n","\n","class ModelCustom(torch.nn.Module):\n","    def __init__(self, n_outputs=5, pretrained=True, freeze=False):\n","        super().__init__()\n","        # Descargar el modelo ResNeSt pretrainado\n","        resnest = timm.create_model('resnest50d', pretrained=pretrained)\n","\n","        # Replace the classifier layer\n","        num_ftrs = resnest.fc.in_features\n","        resnest.fc = torch.nn.Linear(num_ftrs, n_outputs)\n","\n","        self.resnest = resnest\n","\n","        if freeze:\n","            for param in self.resnest.parameters():\n","                param.requires_grad = False\n","            # Ensure the new classifier layer is trainable even if freeze is True\n","            for param in self.resnest.fc.parameters():\n","                param.requires_grad = True\n","\n","\n","    def forward(self, x):\n","        x = self.resnest(x)\n","        return x\n","\n","    def unfreeze(self):\n","        for param in self.resnest.parameters():\n","            param.requires_grad = True"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":2147,"status":"ok","timestamp":1755748139160,"user":{"displayName":"Josè Davìd Quispe Sucullani","userId":"13586411122360630394"},"user_tz":240},"id":"PT89q4yDokAc","outputId":"03c5c790-b522-4afd-e2d7-75a5b003d67e"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c8e63d7254b14cfaa79647042edfd5b9","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/110M [00:00\u003c?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["ModelCustom(\n","  (resnest): ResNet(\n","    (conv1): Sequential(\n","      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (2): ReLU(inplace=True)\n","      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (5): ReLU(inplace=True)\n","      (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    )\n","    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (act1): ReLU(inplace=True)\n","    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","    (layer1): Sequential(\n","      (0): ResNestBottleneck(\n","        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): SplitAttn(\n","          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (drop): Identity()\n","          (act0): ReLU(inplace=True)\n","          (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): ReLU(inplace=True)\n","          (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): RadixSoftmax()\n","        )\n","        (bn2): Identity()\n","        (drop_block): Identity()\n","        (act2): Identity()\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): Identity()\n","          (1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): ResNestBottleneck(\n","        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): SplitAttn(\n","          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (drop): Identity()\n","          (act0): ReLU(inplace=True)\n","          (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): ReLU(inplace=True)\n","          (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): RadixSoftmax()\n","        )\n","        (bn2): Identity()\n","        (drop_block): Identity()\n","        (act2): Identity()\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","      )\n","      (2): ResNestBottleneck(\n","        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): SplitAttn(\n","          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (drop): Identity()\n","          (act0): ReLU(inplace=True)\n","          (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): ReLU(inplace=True)\n","          (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): RadixSoftmax()\n","        )\n","        (bn2): Identity()\n","        (drop_block): Identity()\n","        (act2): Identity()\n","        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","      )\n","    )\n","    (layer2): Sequential(\n","      (0): ResNestBottleneck(\n","        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): SplitAttn(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (drop): Identity()\n","          (act0): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): ReLU(inplace=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): RadixSoftmax()\n","        )\n","        (bn2): Identity()\n","        (drop_block): Identity()\n","        (act2): Identity()\n","        (avd_last): AvgPool2d(kernel_size=3, stride=2, padding=1)\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","          (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): ResNestBottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): SplitAttn(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (drop): Identity()\n","          (act0): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): ReLU(inplace=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): RadixSoftmax()\n","        )\n","        (bn2): Identity()\n","        (drop_block): Identity()\n","        (act2): Identity()\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","      )\n","      (2): ResNestBottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): SplitAttn(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (drop): Identity()\n","          (act0): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): ReLU(inplace=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): RadixSoftmax()\n","        )\n","        (bn2): Identity()\n","        (drop_block): Identity()\n","        (act2): Identity()\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","      )\n","      (3): ResNestBottleneck(\n","        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): SplitAttn(\n","          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (drop): Identity()\n","          (act0): ReLU(inplace=True)\n","          (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): ReLU(inplace=True)\n","          (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): RadixSoftmax()\n","        )\n","        (bn2): Identity()\n","        (drop_block): Identity()\n","        (act2): Identity()\n","        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","      )\n","    )\n","    (layer3): Sequential(\n","      (0): ResNestBottleneck(\n","        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): SplitAttn(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (drop): Identity()\n","          (act0): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): ReLU(inplace=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): RadixSoftmax()\n","        )\n","        (bn2): Identity()\n","        (drop_block): Identity()\n","        (act2): Identity()\n","        (avd_last): AvgPool2d(kernel_size=3, stride=2, padding=1)\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","          (1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): ResNestBottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): SplitAttn(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (drop): Identity()\n","          (act0): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): ReLU(inplace=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): RadixSoftmax()\n","        )\n","        (bn2): Identity()\n","        (drop_block): Identity()\n","        (act2): Identity()\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","      )\n","      (2): ResNestBottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): SplitAttn(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (drop): Identity()\n","          (act0): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): ReLU(inplace=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): RadixSoftmax()\n","        )\n","        (bn2): Identity()\n","        (drop_block): Identity()\n","        (act2): Identity()\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","      )\n","      (3): ResNestBottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): SplitAttn(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (drop): Identity()\n","          (act0): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): ReLU(inplace=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): RadixSoftmax()\n","        )\n","        (bn2): Identity()\n","        (drop_block): Identity()\n","        (act2): Identity()\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","      )\n","      (4): ResNestBottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): SplitAttn(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (drop): Identity()\n","          (act0): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): ReLU(inplace=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): RadixSoftmax()\n","        )\n","        (bn2): Identity()\n","        (drop_block): Identity()\n","        (act2): Identity()\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","      )\n","      (5): ResNestBottleneck(\n","        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): SplitAttn(\n","          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (drop): Identity()\n","          (act0): ReLU(inplace=True)\n","          (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): ReLU(inplace=True)\n","          (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): RadixSoftmax()\n","        )\n","        (bn2): Identity()\n","        (drop_block): Identity()\n","        (act2): Identity()\n","        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","      )\n","    )\n","    (layer4): Sequential(\n","      (0): ResNestBottleneck(\n","        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): SplitAttn(\n","          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (drop): Identity()\n","          (act0): ReLU(inplace=True)\n","          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): ReLU(inplace=True)\n","          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): RadixSoftmax()\n","        )\n","        (bn2): Identity()\n","        (drop_block): Identity()\n","        (act2): Identity()\n","        (avd_last): AvgPool2d(kernel_size=3, stride=2, padding=1)\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","        (downsample): Sequential(\n","          (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","          (1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","          (2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        )\n","      )\n","      (1): ResNestBottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): SplitAttn(\n","          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (drop): Identity()\n","          (act0): ReLU(inplace=True)\n","          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): ReLU(inplace=True)\n","          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): RadixSoftmax()\n","        )\n","        (bn2): Identity()\n","        (drop_block): Identity()\n","        (act2): Identity()\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","      )\n","      (2): ResNestBottleneck(\n","        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (conv2): SplitAttn(\n","          (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","          (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (drop): Identity()\n","          (act0): ReLU(inplace=True)\n","          (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (act1): ReLU(inplace=True)\n","          (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n","          (rsoftmax): RadixSoftmax()\n","        )\n","        (bn2): Identity()\n","        (drop_block): Identity()\n","        (act2): Identity()\n","        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act3): ReLU(inplace=True)\n","      )\n","    )\n","    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n","    (fc): Linear(in_features=2048, out_features=5, bias=True)\n","  )\n",")\n"]}],"source":["# Inicializar el modelo con ResNeSt\n","model = ModelCustom(n_outputs=5, pretrained=True, freeze=False)\n","\n","# Ver la arquitectura del modelo\n","print(model)"]},{"cell_type":"markdown","metadata":{"id":"m1zw7af_TjR5"},"source":["## Cargar el modelo ResNeSt preentrenado\n","\n","Aquí cargamos el modelo ResNet preentrenado y lo adaptamos para la clasificación de nuestras 5 clases de materiales organicos e inorganicos"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":913,"status":"ok","timestamp":1755748140095,"user":{"displayName":"Josè Davìd Quispe Sucullani","userId":"13586411122360630394"},"user_tz":240},"id":"G0Izxpa1Wo4c","outputId":"0ffc5981-1614-4e13-d747-ff7c6bb0f5db"},"outputs":[{"name":"stdout","output_type":"stream","text":["ResNet(\n","  (conv1): Sequential(\n","    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU(inplace=True)\n","    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","  )\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (act1): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): ResNestBottleneck(\n","      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act1): ReLU(inplace=True)\n","      (conv2): SplitAttn(\n","        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","        (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop): Identity()\n","        (act0): ReLU(inplace=True)\n","        (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n","        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n","        (rsoftmax): RadixSoftmax()\n","      )\n","      (bn2): Identity()\n","      (drop_block): Identity()\n","      (act2): Identity()\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act3): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): Identity()\n","        (1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): ResNestBottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act1): ReLU(inplace=True)\n","      (conv2): SplitAttn(\n","        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","        (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop): Identity()\n","        (act0): ReLU(inplace=True)\n","        (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n","        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n","        (rsoftmax): RadixSoftmax()\n","      )\n","      (bn2): Identity()\n","      (drop_block): Identity()\n","      (act2): Identity()\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act3): ReLU(inplace=True)\n","    )\n","    (2): ResNestBottleneck(\n","      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act1): ReLU(inplace=True)\n","      (conv2): SplitAttn(\n","        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","        (bn0): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop): Identity()\n","        (act0): ReLU(inplace=True)\n","        (fc1): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n","        (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (fc2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n","        (rsoftmax): RadixSoftmax()\n","      )\n","      (bn2): Identity()\n","      (drop_block): Identity()\n","      (act2): Identity()\n","      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act3): ReLU(inplace=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): ResNestBottleneck(\n","      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act1): ReLU(inplace=True)\n","      (conv2): SplitAttn(\n","        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","        (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop): Identity()\n","        (act0): ReLU(inplace=True)\n","        (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","        (rsoftmax): RadixSoftmax()\n","      )\n","      (bn2): Identity()\n","      (drop_block): Identity()\n","      (act2): Identity()\n","      (avd_last): AvgPool2d(kernel_size=3, stride=2, padding=1)\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act3): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","        (1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): ResNestBottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act1): ReLU(inplace=True)\n","      (conv2): SplitAttn(\n","        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","        (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop): Identity()\n","        (act0): ReLU(inplace=True)\n","        (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","        (rsoftmax): RadixSoftmax()\n","      )\n","      (bn2): Identity()\n","      (drop_block): Identity()\n","      (act2): Identity()\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act3): ReLU(inplace=True)\n","    )\n","    (2): ResNestBottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act1): ReLU(inplace=True)\n","      (conv2): SplitAttn(\n","        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","        (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop): Identity()\n","        (act0): ReLU(inplace=True)\n","        (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","        (rsoftmax): RadixSoftmax()\n","      )\n","      (bn2): Identity()\n","      (drop_block): Identity()\n","      (act2): Identity()\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act3): ReLU(inplace=True)\n","    )\n","    (3): ResNestBottleneck(\n","      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act1): ReLU(inplace=True)\n","      (conv2): SplitAttn(\n","        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","        (bn0): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop): Identity()\n","        (act0): ReLU(inplace=True)\n","        (fc1): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n","        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (fc2): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n","        (rsoftmax): RadixSoftmax()\n","      )\n","      (bn2): Identity()\n","      (drop_block): Identity()\n","      (act2): Identity()\n","      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act3): ReLU(inplace=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): ResNestBottleneck(\n","      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act1): ReLU(inplace=True)\n","      (conv2): SplitAttn(\n","        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop): Identity()\n","        (act0): ReLU(inplace=True)\n","        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","        (rsoftmax): RadixSoftmax()\n","      )\n","      (bn2): Identity()\n","      (drop_block): Identity()\n","      (act2): Identity()\n","      (avd_last): AvgPool2d(kernel_size=3, stride=2, padding=1)\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act3): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","        (1): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): ResNestBottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act1): ReLU(inplace=True)\n","      (conv2): SplitAttn(\n","        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop): Identity()\n","        (act0): ReLU(inplace=True)\n","        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","        (rsoftmax): RadixSoftmax()\n","      )\n","      (bn2): Identity()\n","      (drop_block): Identity()\n","      (act2): Identity()\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act3): ReLU(inplace=True)\n","    )\n","    (2): ResNestBottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act1): ReLU(inplace=True)\n","      (conv2): SplitAttn(\n","        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop): Identity()\n","        (act0): ReLU(inplace=True)\n","        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","        (rsoftmax): RadixSoftmax()\n","      )\n","      (bn2): Identity()\n","      (drop_block): Identity()\n","      (act2): Identity()\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act3): ReLU(inplace=True)\n","    )\n","    (3): ResNestBottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act1): ReLU(inplace=True)\n","      (conv2): SplitAttn(\n","        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop): Identity()\n","        (act0): ReLU(inplace=True)\n","        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","        (rsoftmax): RadixSoftmax()\n","      )\n","      (bn2): Identity()\n","      (drop_block): Identity()\n","      (act2): Identity()\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act3): ReLU(inplace=True)\n","    )\n","    (4): ResNestBottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act1): ReLU(inplace=True)\n","      (conv2): SplitAttn(\n","        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop): Identity()\n","        (act0): ReLU(inplace=True)\n","        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","        (rsoftmax): RadixSoftmax()\n","      )\n","      (bn2): Identity()\n","      (drop_block): Identity()\n","      (act2): Identity()\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act3): ReLU(inplace=True)\n","    )\n","    (5): ResNestBottleneck(\n","      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act1): ReLU(inplace=True)\n","      (conv2): SplitAttn(\n","        (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","        (bn0): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop): Identity()\n","        (act0): ReLU(inplace=True)\n","        (fc1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n","        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (fc2): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n","        (rsoftmax): RadixSoftmax()\n","      )\n","      (bn2): Identity()\n","      (drop_block): Identity()\n","      (act2): Identity()\n","      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act3): ReLU(inplace=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): ResNestBottleneck(\n","      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act1): ReLU(inplace=True)\n","      (conv2): SplitAttn(\n","        (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","        (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop): Identity()\n","        (act0): ReLU(inplace=True)\n","        (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n","        (rsoftmax): RadixSoftmax()\n","      )\n","      (bn2): Identity()\n","      (drop_block): Identity()\n","      (act2): Identity()\n","      (avd_last): AvgPool2d(kernel_size=3, stride=2, padding=1)\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act3): ReLU(inplace=True)\n","      (downsample): Sequential(\n","        (0): AvgPool2d(kernel_size=2, stride=2, padding=0)\n","        (1): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (2): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): ResNestBottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act1): ReLU(inplace=True)\n","      (conv2): SplitAttn(\n","        (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","        (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop): Identity()\n","        (act0): ReLU(inplace=True)\n","        (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n","        (rsoftmax): RadixSoftmax()\n","      )\n","      (bn2): Identity()\n","      (drop_block): Identity()\n","      (act2): Identity()\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act3): ReLU(inplace=True)\n","    )\n","    (2): ResNestBottleneck(\n","      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act1): ReLU(inplace=True)\n","      (conv2): SplitAttn(\n","        (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n","        (bn0): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (drop): Identity()\n","        (act0): ReLU(inplace=True)\n","        (fc1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (act1): ReLU(inplace=True)\n","        (fc2): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n","        (rsoftmax): RadixSoftmax()\n","      )\n","      (bn2): Identity()\n","      (drop_block): Identity()\n","      (act2): Identity()\n","      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (act3): ReLU(inplace=True)\n","    )\n","  )\n","  (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n","  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",")\n"]}],"source":["import timm\n","\n","# Cargar el modelo ResNeSt preentrenado\n","resnest = timm.create_model('resnest50d', pretrained=True)\n","\n","# Ver la arquitectura del modelo\n","print(resnest)\n"]},{"cell_type":"markdown","metadata":{"id":"OJHg4vdQ4G68"},"source":["# Cargar el modelo preentrenado ResNeSt"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":1188,"status":"ok","timestamp":1755748141309,"user":{"displayName":"Josè Davìd Quispe Sucullani","userId":"13586411122360630394"},"user_tz":240},"id":"po-tmQk1Trdy"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import timm\n","\n","# Configurar el dispositivo\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Cargar el modelo preentrenado ResNeSt\n","modelo = timm.create_model('resnest50d', pretrained=True)\n","\n","# Congelar las capas del modelo para evitar su entrenamiento inicial (Transfer Learning)\n","for param in modelo.parameters():\n","    param.requires_grad = False\n","\n","# Reemplazar la última capa completamente conectada para que coincida con nuestro número de clases\n","num_ftrs = modelo.num_features  # Obtener el número de características de la última capa\n","modelo.fc = nn.Linear(num_ftrs, 5)  # 5 clases de materiales\n","\n","# Mover el modelo al dispositivo adecuado\n","modelo = modelo.to(device)\n"]},{"cell_type":"markdown","metadata":{"id":"6dWUD627VThc"},"source":["##Definir la función de pérdida y el optimizador\n","\n","Aplicaremos la técnica de Fine Tuning, por lo que seleccionamos un optimizador que ajustará solo los parámetros de la última capa."]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1755748141340,"user":{"displayName":"Josè Davìd Quispe Sucullani","userId":"13586411122360630394"},"user_tz":240},"id":"2qmlvKX1rSnz"},"outputs":[],"source":["# Definir la función de pérdida y el optimizador\n","criterio = nn.CrossEntropyLoss()\n","optimizador = optim.AdamW(modelo.parameters(), lr=0.001, weight_decay=0.01)\n"]},{"cell_type":"markdown","metadata":{"id":"ZyiDpIBFVdtw"},"source":["##Entrenamiento del modelo\n","\n","El proceso de entrenamiento incluye la fase de Transfer Learning seguida de Fine Tuning. Primero, entrenaremos solo la última capa y luego desbloquearemos algunas capas adicionales para ajustar todo el modelo."]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":1767,"status":"ok","timestamp":1755748143110,"user":{"displayName":"Josè Davìd Quispe Sucullani","userId":"13586411122360630394"},"user_tz":240},"id":"Saptqm_lrDSF"},"outputs":[],"source":["# Cargar el modelo preentrenado ResNeSt\n","modelo = timm.create_model('resnest50d', pretrained=True)\n","\n","# Congelar las capas del modelo para evitar su entrenamiento inicial (Transfer Learning)\n","for param in modelo.parameters():\n","    param.requires_grad = False\n","\n","# Reemplazar la última capa completamente conectada para que coincida con nuestro número de clases\n","num_ftrs = modelo.num_features  # Obtener el número de características de la última capa\n","modelo.fc = nn.Linear(num_ftrs, 5)  # 5 clases de materiales\n","# Mover el modelo al dispositivo adecuado\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","modelo = modelo.to(device)\n"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":53,"status":"ok","timestamp":1755748143125,"user":{"displayName":"Josè Davìd Quispe Sucullani","userId":"13586411122360630394"},"user_tz":240},"id":"OCK0DMxcVt8L"},"outputs":[],"source":["# Función de entrenamiento\n","import os\n","def entrenar_modelo(modelo, criterion, optimizer, epochs=10, num_checkpoint=5):\n","    for epoch in range(epochs):\n","        modelo.train()\n","        running_loss = 0.0\n","\n","        for inputs, labels in tqdm(trainloader):\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            optimizer.zero_grad()\n","\n","            outputs = modelo(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item() * inputs.size(0)\n","\n","        epoch_loss = running_loss / len(trainloader.dataset)\n","        print(f\"Epoch {epoch+1}/{epochs}, Pérdida: {epoch_loss:.4f}\")\n","\n","        # Guardar el checkpoint cada num_checkpoint epochs\n","        if (epoch + 1) % num_checkpoint == 0:\n","            checkpoint_dir = '/content/drive/MyDrive/Inteligencia-Artificial_2/Laboratorios/Laboratorio_2'\n","            os.makedirs(checkpoint_dir, exist_ok=True) # Create directory if it doesn't exist\n","            checkpoint_path = f'{checkpoint_dir}/checkpoint_resnest_{epoch+1}.pth'\n","            torch.save({\n","                'epoch': epoch + 1,\n","                'model_state_dict': modelo.state_dict(),\n","                'optimizer_state_dict': optimizer.state_dict(),\n","                'loss': epoch_loss,\n","            }, checkpoint_path)\n","            print(f'Checkpoint saved to {checkpoint_path}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"qowTy2PNY0q9"},"outputs":[{"name":"stderr","output_type":"stream","text":["  0%|          | 0/63 [00:00\u003c?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  warnings.warn(\n","100%|██████████| 63/63 [1:40:54\u003c00:00, 96.11s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/5, Pérdida: 1.5682\n"]},{"name":"stderr","output_type":"stream","text":[" 19%|█▉        | 12/63 [19:15\u003c1:21:10, 95.51s/it]"]}],"source":["# Transfer Learning: Entrenar solo la última capa\n","entrenar_modelo(modelo, criterio, optimizador, epochs=5, num_checkpoint=2)\n","\n","# Guardar el modelo completo después del entrenamiento de Transfer Learning\n","modelo_completo_path = '/content/drive/MyDrive/Inteligencia-Artificial_2/Laboratorios/Laboratorio_2/modelo_transfer_learning.pth'\n","torch.save(modelo.state_dict(), modelo_completo_path)\n","print(f'Modelo entrenado guardado en {modelo_completo_path}')"]},{"cell_type":"markdown","metadata":{"id":"nNwAjKNAoYa6"},"source":["##**FINE TUNING**\n","\n","El fine tinig es para descongelas algunas capas para entrenar con todo el modelo."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jfHg5PlgoXlj"},"outputs":[],"source":["# Desbloquear todas las capas para Fine Tuning\n","for param in modelo.parameters():\n","    param.requires_grad = True\n","\n","# Definir el optimizador para Fine Tuning\n","optimizador = optim.AdamW(modelo.parameters(), lr=0.0001, weight_decay=0.01)\n","\n","# Reentrenar con Fine Tuning\n","entrenar_modelo(modelo, criterio, optimizador, epochs=10, num_checkpoint=5)\n","\n","# Guardar el modelo completo después del Fine Tuning\n","modelo_completo_path = '/content/drive/MyDrive/Inteligencia-Artificial_2/Laboratorios/Laboratorio_2/modelo_fine_tuned.pth'\n","torch.save(modelo.state_dict(), modelo_completo_path)\n","print(f'Modelo fine-tuned guardado en {modelo_completo_path}')"]},{"cell_type":"markdown","metadata":{"id":"ZhxVOIxU3TU5"},"source":["##CARGAMOS LOS MODELOS ENTRENADOS."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VE3K7Fui3W-B"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import copy\n","\n","# Assuming 'modelo' is the original ResNet model architecture\n","modelo_transf_lear = copy.deepcopy(modelo)  # Create a new instance of the model\n","modelo_transf_lear.load_state_dict(torch.load('/content/drive/MyDrive/Inteligencia-Artificial_2/Laboratorios/Laboratorio_2/modelo_transfer_learning.pth'))\n","modelo_transf_lear.eval()  # Now you can call eval() on the new model instance\n","\n","# Use modelo_transf_lear for further operations"]},{"cell_type":"markdown","metadata":{"id":"GVslRJDpV2vT"},"source":["##Evaluar el modelo"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vkX627TaV2CM"},"outputs":[],"source":["def evaluar_modelo(modelo):\n","    modelo.eval()\n","    correctos = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for inputs, labels in testloader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = modelo(inputs)\n","            _, predicciones = torch.max(outputs, 1)\n","            total += labels.size(0)\n","            correctos += (predicciones == labels).sum().item()\n","\n","    precision = 100 * correctos / total\n","    print(f\"Precisión en el conjunto de prueba: {precision:.2f}%\")\n","\n","evaluar_modelo(modelo_transf_lear)\n"]},{"cell_type":"markdown","metadata":{"id":"EdenuVaN6Qoh"},"source":["##PRUEBAS CON UNA IMAGEN FOTOGRÁFICA"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PWqX8s4B6UrP"},"outputs":[],"source":["import torch\n","from torchvision import transforms\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","\n","# Definir las transformaciones para las imágenes (debe coincidir con las del entrenamiento)\n","transform = transforms.Compose([\n","    transforms.Resize((50, 50)),  # Reducir el tamaño de la imagen a 50x50 píxeles\n","    transforms.ToTensor(),  # Convertir las imágenes a tensores\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalizar los tensores\n","])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wm3Mlk196bMQ"},"outputs":[],"source":["# Función para hacer predicciones\n","def predict_image(image_path):\n","    # Cargar la imagen\n","    image = Image.open(image_path)\n","\n","    # Aplicar las transformaciones\n","    image_tensor = transform(image).unsqueeze(0)  # Añadir una dimensión para el batch\n","\n","    # Mover el tensor de la imagen al mismo dispositivo que el modelo\n","    image_tensor = image_tensor.to(modelo_transf_lear.fc.weight.device)\n","\n","    # Realizar la predicción\n","    with torch.no_grad():\n","        outputs = modelo_transf_lear(image_tensor)\n","        _, predicted = torch.max(outputs, 1)\n","\n","    return predicted.item()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0qN4GpaK6gGl"},"outputs":[],"source":["# Ruta de la imagen a probar\n","# image_path = ''  # Cambia esto a la ruta de tu imagen\n","# image_path = ''\n","# image_path = ''\n","# image_path = ''\n","image_path = '/content/drive/MyDrive/Inteligencia-Artificial_2/Laboratorios/Laboratorio_2/Dataset/train/Cable-De-Red/imagen_6000.jpg'\n","\n","# Obtener la clase predicha\n","predicted_class = predict_image(image_path)\n","\n","# Mostrar la imagen y el resultado\n","image = Image.open(image_path)\n","plt.imshow(image)\n","plt.title(f'Predicted Class: {predicted_class}')\n","plt.axis('off')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CrP1NH0M6j5N"},"outputs":[],"source":["# OTRAS MANERA DE PREDECIR EL MODELO\n","\n","# Cargar la imagen para prueba\n","def load_image(image_path):\n","    image = Image.open(image_path).convert('RGB')\n","    image = transform(image).unsqueeze(0)  # Añadir una dimensión para el batch\n","    return image\n","\n","# Realizar una prueba con una imagen cargada\n","def predict(image_path):\n","    image = load_image(image_path)\n","    # Mover el tensor de la imagen al mismo dispositivo que el modelo\n","    image = image.to(device)\n","    with torch.no_grad():\n","        outputs = modelo_transf_lear(image)\n","        _, predicted = torch.max(outputs.data, 1)\n","        return predicted.item()\n","\n","# Ejemplo de uso\n","image_path = '/content/drive/MyDrive/Inteligencia-Artificial_2/Laboratorios/Laboratorio_2/Dataset/train/Bolsas-Soda/imagen_2868.jpg'\n","predicted_class = predict(image_path)\n","print(f'Predicted class: {predicted_class}')"]},{"cell_type":"markdown","metadata":{"id":"OpZuQbm7XDM8"},"source":["##PROBANDO OTRAS MANERA DE ENTRENAMIENTO DEL MODELO CON TRANSFER LEARNING"]},{"cell_type":"markdown","metadata":{"id":"S8sQtwZ7XSaw"},"source":["##Transfer Learning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CYuYlEFzXCv8"},"outputs":[],"source":["from tqdm import tqdm\n","import numpy as np\n","import torch.optim as optim\n","import torch.nn as nn\n","import os\n","\n","def fit(model, dataloader_train, dataloader_test, epochs=5, lr=1e-2):\n","    model.to(device)\n","    optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n","    criterion = torch.nn.CrossEntropyLoss()\n","\n","    history = {\n","        'train_loss': [],\n","        'train_acc': [],\n","        'val_loss': [],\n","        'val_acc': []\n","    }\n","\n","    for epoch in range(1, epochs+1):\n","        model.train()\n","        train_loss, train_acc = [], []\n","        bar = tqdm(dataloader_train)\n","        for batch in bar:\n","            X, y = batch\n","            X, y = X.to(device), y.to(device)\n","            optimizer.zero_grad()\n","            y_hat = model(X)\n","            loss = criterion(y_hat, y)\n","            loss.backward()\n","            optimizer.step()\n","            train_loss.append(loss.item())\n","            acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n","            train_acc.append(acc)\n","            bar.set_description(f\"loss {np.mean(train_loss):.5f} acc {np.mean(train_acc):.5f}\")\n","\n","        bar = tqdm(dataloader_test)\n","        val_loss, val_acc = [], []\n","        model.eval()\n","        with torch.no_grad():\n","            for batch in bar:\n","                X, y = batch\n","                X, y = X.to(device), y.to(device)\n","                y_hat = model(X)\n","                loss = criterion(y_hat, y)\n","                val_loss.append(loss.item())\n","                acc = (y == torch.argmax(y_hat, axis=1)).sum().item() / len(y)\n","                val_acc.append(acc)\n","                bar.set_description(f\"val_loss {np.mean(val_loss):.5f} val_acc {np.mean(val_acc):.5f}\")\n","\n","        avg_train_loss = np.mean(train_loss)\n","        avg_train_acc = np.mean(train_acc)\n","        avg_val_loss = np.mean(val_loss)\n","        avg_val_acc = np.mean(val_acc)\n","\n","        print(f\"Epoch {epoch}/{epochs} loss {avg_train_loss:.5f} val_loss {avg_val_loss:.5f} acc {avg_train_acc:.5f} val_acc {avg_val_acc:.5f}\")\n","\n","        history['train_loss'].append(avg_train_loss)\n","        history['train_acc'].append(avg_train_acc)\n","        history['val_loss'].append(avg_val_loss)\n","        history['val_acc'].append(avg_val_acc)\n","\n","    # Guardar el modelo completo al final del entrenamiento\n","    checkpoint_dir = '/content/drive/MyDrive/Inteligencia-Artificial_2/Laboratorios/Laboratorio_2'\n","    os.makedirs(checkpoint_dir, exist_ok=True)\n","    checkpoint_path = os.path.join(checkpoint_dir, 'model_checkpoint.pth')\n","    torch.save({\n","        'epoch': epochs,\n","        'model_state_dict': model.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict(),\n","        'loss': avg_val_loss,\n","    }, checkpoint_path)\n","    print(f'Modelo completo guardado en {checkpoint_path}')\n","    return history"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4odWyidhXWWE"},"outputs":[],"source":["model_c = ModelCustom(pretrained=True, freeze=True)\n","fit(model_c, trainloader, testloader)"]},{"cell_type":"markdown","metadata":{"id":"M2sQ4RtXXkm0"},"source":["##Fine Runing\n","\n","Todavía podemos mejorar un poco más si, además de utilizar los pesos descargados de Imagenet en resnet, entrenamos también la red completa."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EoJEr_cXXn5t"},"outputs":[],"source":["model_c = ModelCustom(pretrained=True, freeze=False)\n","fit(model_c, trainloader, testloader)"]},{"cell_type":"markdown","metadata":{"id":"agVg0ioFXtQw"},"source":["Es común entrenar primero el modelo sin entrenar la red pre-entrenada durante varias epochs y después seguir entrenando, pero permitiendo ahora la actualización de pesos también en la red pre-entrenada (usualmente con un learning rate más pequeño)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o-rwSQKtXvdd"},"outputs":[],"source":["model_o = ModelCustom(pretrained=True, freeze=True)\n","fit(model_o, trainloader, testloader)\n","model_o.unfreeze()\n","fit(model_o, trainloader, testloader, lr=1e-4)"]},{"cell_type":"markdown","metadata":{"id":"O-EyLMWuMNXa"},"source":["Cargamos el modelo entrenado"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r9B7e-WyMQiT"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import copy\n","\n","# Assuming 'modelo' is the original ResNet model architecture\n","model_transf_lear2 = copy.deepcopy(modelo)  # Create a new instance of the model\n","checkpoint = torch.load('/content/drive/MyDrive/Inteligencia-Artificial_2/Laboratorios/Laboratorio_2/modelo_transfer_learning.pth') # Load the checkpoint\n","\n","# Print the keys of the checkpoint and the model's state_dict to compare\n","print(\"Checkpoint keys:\", checkpoint['model_state_dict'].keys())\n","print(\"Model state_dict keys:\", model_transf_lear2.state_dict().keys())\n","\n","\n","new_state_dict = {}\n","for key, value in checkpoint['model_state_dict'].items():\n","    # Example: Removing a 'resnet.' prefix from checkpoint keys if it exists\n","    new_key = key.replace('resnet.', '')\n","    new_state_dict[new_key] = value\n","\n","# Load the modified state dictionary\n","model_transf_lear2.load_state_dict(new_state_dict, strict=False) # Set strict=False to ignore missing keys if needed\n","model_transf_lear2.eval()\n","\n","# Use model_transf_lear2 for further operations"]},{"cell_type":"markdown","metadata":{"id":"V4d12m5lOG8J"},"source":["##Evaluación del modelo."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yb77Gg_fOD3z"},"outputs":[],"source":["def evaluar_modelo(modelo):\n","    modelo.eval()\n","    correctos = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for inputs, labels in testloader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            outputs = modelo(inputs)\n","            _, predicciones = torch.max(outputs, 1)\n","            total += labels.size(0)\n","            correctos += (predicciones == labels).sum().item()\n","\n","    precision = 100 * correctos / total\n","    print(f\"Precisión en el conjunto de prueba: {precision:.2f}%\")\n","\n","evaluar_modelo(model_transf_lear2)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vG0FTuL1PTAu"},"outputs":[],"source":["# Función para hacer predicciones\n","def predict_image2(image_path):\n","    # Cargar la imagen\n","    image = Image.open(image_path)\n","\n","    # Aplicar las transformaciones\n","    image_tensor = transform(image).unsqueeze(0)  # Añadir una dimensión para el batch\n","\n","    # Realizar la predicción\n","    with torch.no_grad():\n","        outputs = model_transf_lear2(image_tensor)\n","        _, predicted = torch.max(outputs, 1)\n","\n","    return predicted.item()"]},{"cell_type":"markdown","metadata":{"id":"fmu5QMK2OWfY"},"source":["##Hacemos pruebas con imagenes fotograficas del datasets creado con residuos organicos e inorganicos"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ir4mbqniOV8B"},"outputs":[],"source":["# Ruta de la imagen a probar\n","# image_path = '/content/drive/MyDrive/SIS420-IA2/Laboratorios/LAB-03/Images_prueba/acelga_08989.jpg'  # Cambia esto a la ruta de tu imagen\n","# image_path = '/content/drive/MyDrive/SIS420-IA2/Laboratorios/LAB-03/Images_prueba/cebolla_00386.jpg'\n","image_path = '/content/drive/MyDrive/Inteligencia-Artificial_2/Laboratorios/Laboratorio_2/Dataset/train/Cable-De-Red/imagen_6001.jpg'\n","# image_path = '/content/drive/MyDrive/SIS420-IA2/Laboratorios/LAB-03/Images_prueba/lechuga_00066.jpg'\n","# image_path = '/content/drive/MyDrive/SIS420-IA2/Laboratorios/LAB-03/Images_prueba/toronjil_00022.jpg'\n","\n","# Obtener la clase predicha\n","predicted_class = predict_image2(image_path)\n","\n","# Mostrar la imagen y el resultado\n","image = Image.open(image_path)\n","plt.imshow(image)\n","plt.title(f'Predicted Class: {predicted_class}')\n","plt.axis('off')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"r3bhh8YYVhZ3"},"source":["##DETALLES\n","\n","- Transfer Learning: Se ha aplicado al congelar las capas iniciales del modelo preentrenado ResNet y solo entrenar la última capa completamente conectada.\n","\n","- Fine Tuning: Se ha realizado desbloqueando las capas adicionales del modelo y ajustándolas mediante el optimizador.\n","\n","- Regularización y Buenas Prácticas: Se han aplicado técnicas como la normalización de imágenes, optimización con SGD y el uso de DataLoader para una carga eficiente de datos."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0bcbddd9"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","def plot_history(history):\n","    plt.figure(figsize=(12, 4))\n","    plt.subplot(1, 2, 1)\n","    plt.plot(history['train_loss'], label='Training Loss')\n","    plt.plot(history['val_loss'], label='Validation Loss')\n","    plt.title('Loss over Epochs')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","\n","    plt.subplot(1, 2, 2)\n","    plt.plot(history['train_acc'], label='Training Accuracy')\n","    plt.plot(history['val_acc'], label='Validation Accuracy')\n","    plt.title('Accuracy over Epochs')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Accuracy')\n","    plt.legend()\n","\n","    plt.show()\n","\n","# Assuming you have a 'history' object from your training\n","# plot_history(history) # Uncomment this line after you have trained the model and have a history object"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0afafd9b5ea4482e81079139666d3f90":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1a6aecff311d45d7a074636f1b68d44d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a89c1a27e0e4bbcb8a9280d22e2e30d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5373fff51b5a485e87a48ef9540cfadd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a89c1a27e0e4bbcb8a9280d22e2e30d","placeholder":"​","style":"IPY_MODEL_fe4ac2f92e9b4b61b8fa2aa918bc5ecd","value":"model.safetensors: 100%"}},"5764919ef12b442da23259d68fa16dbd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a6aecff311d45d7a074636f1b68d44d","max":110235808,"min":0,"orientation":"horizontal","style":"IPY_MODEL_af392e2b1b444efea7056d9f3b3df18a","value":110235808}},"af392e2b1b444efea7056d9f3b3df18a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c25fbbb27de2458aa9ef39c5b2bb6e57":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8e63d7254b14cfaa79647042edfd5b9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5373fff51b5a485e87a48ef9540cfadd","IPY_MODEL_5764919ef12b442da23259d68fa16dbd","IPY_MODEL_e514654c6e2a41eb8b1780027dd15932"],"layout":"IPY_MODEL_0afafd9b5ea4482e81079139666d3f90"}},"c9137e53a657482ba49581ed6ca7cf41":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e514654c6e2a41eb8b1780027dd15932":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c25fbbb27de2458aa9ef39c5b2bb6e57","placeholder":"​","style":"IPY_MODEL_c9137e53a657482ba49581ed6ca7cf41","value":" 110M/110M [00:00\u0026lt;00:00, 220MB/s]"}},"fe4ac2f92e9b4b61b8fa2aa918bc5ecd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}